{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu1-20fhaggK"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example 🔥 </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDmuXg75aggM"
      },
      "source": [
        "# Gesture Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/Gesture_Detection_Swift-YOLO_192.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [Gesture](https://universe.roboflow.com/rsp/paper-aaj0p/dataset/33)\n",
        "\n",
        "**Class:** `paper`, `rock`, `scissors`\n",
        "\n",
        "![Gesture Detection](https://files.seeedstudio.com/sscma/static/detection_gesture.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the gesture detection dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI4n9-_IaggM"
      },
      "source": [
        "## ⚙️Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMZ1Ltu-aggM",
        "outputId": "e4aa0df0-c64e-4c20-e494-f6a6b8835d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 8527, done.\u001b[K\n",
            "remote: Counting objects: 100% (1560/1560), done.\u001b[K\n",
            "remote: Compressing objects: 100% (486/486), done.\u001b[K\n",
            "remote: Total 8527 (delta 1233), reused 1074 (delta 1074), pack-reused 6967\u001b[K\n",
            "Receiving objects: 100% (8527/8527), 18.59 MiB | 25.94 MiB/s, done.\n",
            "Resolving deltas: 100% (5198/5198), done.\n",
            "/content/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.6-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.2.1+cu121\n",
            "    Uninstalling torchaudio-2.2.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Installing base deps... Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from -r requirements/export.txt (line 2))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 2)) (1.3.1)\n",
            "Collecting libusb1 (from -r requirements/base.txt (line 3))\n",
            "  Downloading libusb1-3.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m775.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cbor (from -r requirements/base.txt (line 7))\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 8)) (1.25.2)\n",
            "Collecting opencv-python>=4.9.0.80 (from -r requirements/base.txt (line 12))\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openmim>=0.3.7 (from -r requirements/base.txt (line 16))\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 17)) (24.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 18)) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 19)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 20)) (6.0.1)\n",
            "Collecting scikit-image>=0.20.0 (from -r requirements/base.txt (line 21))\n",
            "  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 22)) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 26)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 30)) (2.15.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 31)) (4.66.4)\n",
            "Collecting pyvww (from -r requirements/base.txt (line 35))\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Collecting pnnx==0.0.4 (from -r requirements/inference.txt (line 2))\n",
            "  Downloading pnnx-0.0.4-py3-none-any.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ncnn>=1.0.20230517 (from -r requirements/inference.txt (line 3))\n",
            "  Downloading ncnn-1.0.20240410-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.14.0 (from -r requirements/inference.txt (line 4))\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxmltools>=1.11.2 (from -r requirements/inference.txt (line 5))\n",
            "  Downloading onnxmltools-1.12.0-py2.py3-none-any.whl (329 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.15.1 (from -r requirements/inference.txt (line 6))\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxsim>=0.4.33 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 8))\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Collecting ethos-u-vela (from -r requirements/export.txt (line 8))\n",
            "  Downloading ethos-u-vela-3.11.0.tar.gz (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.8/404.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black>=23.3.0 (from -r requirements/tests.txt (line 1))\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements/tests.txt (line 2))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pre-commit>=3.3.3 (from -r requirements/tests.txt (line 3))\n",
            "  Downloading pre_commit-3.7.1-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruff>=0.0.275 (from -r requirements/tests.txt (line 4))\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (4.9.0.80)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (8.1.7)\n",
            "Collecting colorama (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (13.7.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2024.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (3.3)\n",
            "Collecting imageio>=2.33 (from scikit-image>=0.20.0->-r requirements/base.txt (line 21))\n",
            "  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (2024.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->-r requirements/base.txt (line 26)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.0.3)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (2.0.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (0.15.1)\n",
            "Collecting portalocker (from ncnn>=1.0.20230517->-r requirements/inference.txt (line 3))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.3.0)\n",
            "Collecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 8))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Collecting ruamel.yaml>=0.16.12 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting igraph>=0.9 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading igraph-0.11.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->-r requirements/export.txt (line 8)) (4.9.4)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (4.2.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (2.0.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading identify-2.5.36-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements/base.txt (line 26)) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.3.1)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2024.2.2)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (2.1.5)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set (from model-index->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (18.1.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.2.2)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard>=2.12.3->-r requirements/base.txt (line 30))\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.65.0 (from -r requirements/base.txt (line 31))\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16)) (42.0.7)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'pnnx' candidate (version 0.0.4 at https://files.pythonhosted.org/packages/2a/61/e70626f1e94026da417e6ecd5ad303d0ef3fe7a32fb3fff821bb07f1f4e2/pnnx-0.0.4-py3-none-any.whl (from https://pypi.org/simple/pnnx/))\n",
            "Reason for being yanked: <none given>\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: cbor, ethos-u-vela, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53431 sha256=79d8ae3e0c0cd256705dcbe6df482f4439ed676f0a4525ca98afc14af5b49cd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "  Building wheel for ethos-u-vela (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-3.11.0-cp310-cp310-linux_x86_64.whl size=619666 sha256=b9c2c13247211356a0b38683df6918fcb4b67f7c6a0a5d141141ba95062d5592\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/28/52/49ff4373dfce5867eb0f956a19f7ef55c7cdb4929b4a65732d\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=76756f32fac3c7d753582339ee42d7ce107d493105ca4f545acb6f674539635d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=9390c98b3e549379ac3c35abcd124765dfab768161800d45da667a208b0d8dea\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=f478bec5d8f4197c2748af71b151eaec8347c037042df4c8f39e22f80a65bc88\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built cbor ethos-u-vela oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: texttable, pnnx, libusb1, flatbuffers, distlib, crcmod, cbor, virtualenv, urllib3, tqdm, setuptools, ruff, ruamel.yaml.clib, pycryptodome, protobuf, portalocker, pathspec, ordered-set, opencv-python, mypy-extensions, jmespath, isort, imageio, igraph, identify, humanfriendly, ethos-u-vela, colorama, cfgv, scikit-image, ruamel.yaml, rich, requests, onnx, nodeenv, model-index, coloredlogs, black, TinyNeuralNetwork, pre-commit, onnxsim, onnxruntime, onnxmltools, ncnn, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim, pyvww\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.1\n",
            "    Uninstalling rich-13.7.1:\n",
            "      Successfully uninstalled rich-13.7.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.4 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "yfinance 0.2.38 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TinyNeuralNetwork-0.1.1 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 black-24.4.2 cbor-1.0.0 cfgv-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 crcmod-1.7 distlib-0.3.8 ethos-u-vela-3.11.0 flatbuffers-23.5.26 humanfriendly-10.0 identify-2.5.36 igraph-0.11.5 imageio-2.34.1 isort-5.13.2 jmespath-0.10.0 libusb1-3.1.0 model-index-0.1.11 mypy-extensions-1.0.0 ncnn-1.0.20240410 nodeenv-1.8.0 onnx-1.16.0 onnxmltools-1.12.0 onnxruntime-1.18.0 onnxsim-0.4.36 opencv-python-4.9.0.80 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.38 ordered-set-4.1.0 oss2-2.17.0 pathspec-0.12.1 pnnx-0.0.4 portalocker-2.8.2 pre-commit-3.7.1 protobuf-4.25.3 pycryptodome-3.20.0 pyvww-0.1.1 requests-2.28.2 rich-13.4.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 ruff-0.4.4 scikit-image-0.23.2 setuptools-60.2.0 texttable-1.7.0 tqdm-4.65.2 urllib3-1.26.18 virtualenv-20.26.2\n",
            "Installing OpenMIM deps... \n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcls>=1.0.0.rc6 (from -r requirements/mmlab.txt (line 2))\n",
            "  Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl (906 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.1/906.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmcv-full<=2.1.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv_full-1.7.2-cp310-cp310-manylinux1_x86_64.whl (70.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmdet<3.1.0,>=3.0.0 (from -r requirements/mmlab.txt (line 4))\n",
            "  Downloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmengine>=0.8.2 (from -r requirements/mmlab.txt (line 5))\n",
            "  Downloading mmengine-0.10.4-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.7.1)\n",
            "Collecting modelindex (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (13.4.2)\n",
            "Collecting mmcv<=2.1.0,>=2.0.0rc4 (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (6.0.1)\n",
            "Collecting yapf (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.9.0.80)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.16.0)\n",
            "Collecting terminaltables (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4))\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Collecting mmcv<=2.1.0,>=2.0.0rc4 (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->-r requirements/mmlab.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (7.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.2.1)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (3.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (8.1.7)\n",
            "Installing collected packages: addict, terminaltables, yapf, modelindex, mmengine, mmcv-full, mmcv, mmdet, mmcls\n",
            "Successfully installed addict-2.4.0 mmcls-1.0.0rc6 mmcv-2.0.1 mmcv-full-1.7.2 mmdet-3.0.0 mmengine-0.10.4 modelindex-0.0.2 terminaltables-3.1.10 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Obtaining file:///content/ModelAssistant\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "Requirement already satisfied: torch<=2.0.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: torchaudio<=2.0.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: torchvision<=0.15.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.15.1)\n",
            "Requirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: libusb1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.1.0)\n",
            "Requirement already satisfied: cbor in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.9.0.80)\n",
            "Requirement already satisfied: openmim>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (6.0.1)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.65.2)\n",
            "Requirement already satisfied: pyvww in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: pnnx==0.0.4 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: ncnn>=1.0.20230517 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.20240410)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: onnxmltools>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.12.0)\n",
            "Requirement already satisfied: onnxruntime>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.18.0)\n",
            "Requirement already satisfied: onnxsim>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.4.36)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.25.3)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.11.0)\n",
            "Requirement already satisfied: black>=23.3.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.4.2)\n",
            "Requirement already satisfied: isort>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (5.13.2)\n",
            "Requirement already satisfied: pre-commit>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.7.1)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.4.4)\n",
            "Requirement already satisfied: mmcls>=1.0.0.rc6 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0rc6)\n",
            "Requirement already satisfied: mmcv-full<=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.7.2)\n",
            "Requirement already satisfied: mmdet<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: mmengine>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.10.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (4.9.0.80)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.2.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.7.1)\n",
            "Requirement already satisfied: modelindex in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (13.4.2)\n",
            "Requirement already satisfied: mmcv<=2.1.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (0.40.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.7)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (3.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.28.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.12)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.0.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (23.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2024.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (2.5.36)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (20.26.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2.34.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2024.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.1->sscma==2.0.0rc3) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (18.1.6)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->sscma==2.0.0rc3) (4.9.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.18.6)\n",
            "Requirement already satisfied: igraph>=0.9 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.11.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->sscma==2.0.0rc3) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (2024.2.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.2.8)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->sscma==2.0.0rc3) (0.3.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->sscma==2.0.0rc3) (2.1.5)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.15.1->sscma==2.0.0rc3) (10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.1.2)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim>=0.3.7->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (3.20.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.0.38)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->sscma==2.0.0rc3) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full<=2.1.0->sscma==2.0.0rc3) (3.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (3.2.2)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.17.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.3)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.15.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (42.0.7)\n",
            "Building wheels for collected packages: sscma\n",
            "  Building editable for sscma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sscma: filename=sscma-2.0.0rc3-0.editable-py3-none-any.whl size=9400 sha256=cddf7e295a8058678aea78ab097f8f4b64c0f02942395084b94baee43c303570\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-holos28u/wheels/90/1c/ba/0dcfb496beef1b933cf590042cc252e1a365a514ee48989a82\n",
            "Successfully built sscma\n",
            "Installing collected packages: sscma\n",
            "Successfully installed sscma-2.0.0rc3\n",
            "Finished setup... \u001b[032mOK\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git   #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TvayLv-aggN"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC1_f1fUaggN",
        "outputId": "dccca6e9-be01-4bb2-a7d6-0f7de22618c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-21 00:03:06--  https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 13.32.164.59, 13.32.164.38, 13.32.164.111, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|13.32.164.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12822891 (12M) [application/octet-stream]\n",
            "Saving to: ‘Gesture_Detection_Swift-YOLO_192/pretrain.pth’\n",
            "\n",
            "Gesture_Detection_S 100%[===================>]  12.23M  29.9MB/s    in 0.4s    \n",
            "\n",
            "2024-05-21 00:03:07 (29.9 MB/s) - ‘Gesture_Detection_Swift-YOLO_192/pretrain.pth’ saved [12822891/12822891]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth -O Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFdeadnKaggN"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z39a1Jn-aggN",
        "outputId": "db440feb-452a-4ca2-aa96-ef95d41fed89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-21 00:03:27--  https://universe.roboflow.com/ds/xaMM3ZTeWy?key=5bznPZyI0t\n",
            "Resolving universe.roboflow.com (universe.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to universe.roboflow.com (universe.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/6wojE7svfZ8Lhy4WFzQ3/4QAjh8ko3NJg608ogyfz/33/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240521%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240521T000327Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=4780450d9f8d1878cb8c522437695f840f27cb2131cab3100260e44e8d407cfea5aa945111758fd8e0f170b5265b6d5cf4978231ec4578b09e7cb51bf78e6072977697930ac89c89309786bbf0bf61a4c706888171d80e6012abc04af0b61adfa71ff46035e9e95f46c7fa237cbfebf219e587487b1d929a86cfd647420363b3dd42fc5d355ff498270a3d620ac36386b85f57cbbc50858946ba3978866f3becf678aea52cabc9f2b617b5512a179622918b8c5b126f1c8b8f5e16deb5fbcb500af19067bbbf411aedc8cab118ecc20ebeb4073d1ac81e9f8344ecbb7551ab3d09670035ba587baf951047cf4cf247b5200148f6abcc6fcbfa415b1f01186546 [following]\n",
            "--2024-05-21 00:03:27--  https://storage.googleapis.com/roboflow-platform-regional-exports/6wojE7svfZ8Lhy4WFzQ3/4QAjh8ko3NJg608ogyfz/33/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240521%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240521T000327Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=4780450d9f8d1878cb8c522437695f840f27cb2131cab3100260e44e8d407cfea5aa945111758fd8e0f170b5265b6d5cf4978231ec4578b09e7cb51bf78e6072977697930ac89c89309786bbf0bf61a4c706888171d80e6012abc04af0b61adfa71ff46035e9e95f46c7fa237cbfebf219e587487b1d929a86cfd647420363b3dd42fc5d355ff498270a3d620ac36386b85f57cbbc50858946ba3978866f3becf678aea52cabc9f2b617b5512a179622918b8c5b126f1c8b8f5e16deb5fbcb500af19067bbbf411aedc8cab118ecc20ebeb4073d1ac81e9f8344ecbb7551ab3d09670035ba587baf951047cf4cf247b5200148f6abcc6fcbfa415b1f01186546\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 64.233.181.207, 64.233.183.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10659199 (10M) [application/zip]\n",
            "Saving to: ‘Gesture_Detection_Swift-YOLO_192/dataset.zip’\n",
            "\n",
            "Gesture_Detection_S 100%[===================>]  10.17M  39.2MB/s    in 0.3s    \n",
            "\n",
            "2024-05-21 00:03:28 (39.2 MB/s) - ‘Gesture_Detection_Swift-YOLO_192/dataset.zip’ saved [10659199/10659199]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192/dataset\n",
        "!wget -c https://universe.roboflow.com/ds/xaMM3ZTeWy?key=5bznPZyI0t -O Gesture_Detection_Swift-YOLO_192/dataset.zip\n",
        "!unzip -q Gesture_Detection_Swift-YOLO_192/dataset.zip -d Gesture_Detection_Swift-YOLO_192/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKcAc8ZraggO"
      },
      "source": [
        "## 🚀Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXT53vTlaggO",
        "outputId": "21d6e17e-333a-40cb-a054-68aa54b94ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "05/21 00:08:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 407344432\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.9.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 407344432\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/21 00:08:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20240521_000823'}\n",
            "2024-05-21 00:08:27.632629: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-21 00:08:27.632683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-21 00:08:27.764639: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-21 00:08:30.570083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/21 00:08:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/21 00:08:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[1, 3, 192, 192]\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add encountered 24 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul encountered 18 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::clone encountered 3 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sub encountered 3 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul_ encountered 6 time(s)\n",
            "05/21 00:08:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "bbox_head.head_module.data_preprocessor, bbox_head.loss_bbox, bbox_head.loss_cls, bbox_head.loss_obj, data_preprocessor\n",
            "05/21 00:08:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 85 time(s)\n",
            "05/21 00:08:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::upsample_nearest2d encountered 2 time(s)\n",
            "\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "| model                                        | 0.945M               | 0.126G     | 1.059M       |\n",
            "|  backbone                                    |  0.66M               |  0.101G    |  0.868M      |\n",
            "|   backbone.stem.conv                         |   1.76K              |   16.22M   |   0.147M     |\n",
            "|    backbone.stem.conv.conv                   |    1.728K            |    15.925M |    0.147M    |\n",
            "|    backbone.stem.conv.norm                   |    32                |    0.295M  |    0         |\n",
            "|   backbone.stage1                            |   9.216K             |   21.234M  |   0.332M     |\n",
            "|    backbone.stage1.0.conv                    |    3.504K            |    8.073M  |    55.296K   |\n",
            "|    backbone.stage1.1                         |    5.712K            |    13.16M  |    0.276M    |\n",
            "|   backbone.stage2                            |   36.56K             |   21.059M  |   0.207M     |\n",
            "|    backbone.stage2.0.conv                    |    8.72K             |    5.023M  |    23.04K    |\n",
            "|    backbone.stage2.1                         |    27.84K            |    16.036M |    0.184M    |\n",
            "|   backbone.stage3                            |   0.188M             |   27.003M  |   0.138M     |\n",
            "|    backbone.stage3.0.conv                    |    28.96K            |    4.17M   |    11.52K    |\n",
            "|    backbone.stage3.1                         |    0.159M            |    22.833M |    0.127M    |\n",
            "|   backbone.stage4                            |   0.425M             |   15.293M  |   43.2K      |\n",
            "|    backbone.stage4.0.conv                    |    0.116M            |    4.159M  |    5.76K     |\n",
            "|    backbone.stage4.1                         |    0.245M            |    8.813M  |    28.8K     |\n",
            "|    backbone.stage4.2                         |    64.48K            |    2.321M  |    8.64K     |\n",
            "|  neck                                        |  0.279M              |  23.881M   |  0.173M      |\n",
            "|   neck.reduce_layers.2.conv                  |   12.96K             |   0.467M   |   2.88K      |\n",
            "|    neck.reduce_layers.2.conv.conv            |    12.8K             |    0.461M  |    2.88K     |\n",
            "|    neck.reduce_layers.2.conv.norm            |    0.16K             |    5.76K   |    0         |\n",
            "|   neck.top_down_layers                       |   48K                |   10.817M  |   0.109M     |\n",
            "|    neck.top_down_layers.0                    |    38.96K            |    5.61M   |    40.32K    |\n",
            "|    neck.top_down_layers.1                    |    9.04K             |    5.207M  |    69.12K    |\n",
            "|   neck.downsample_layers                     |   72.24K             |   4.164M   |   8.64K      |\n",
            "|    neck.downsample_layers.0.conv             |    14.48K            |    2.085M  |    5.76K     |\n",
            "|    neck.downsample_layers.1.conv             |    57.76K            |    2.079M  |    2.88K     |\n",
            "|   neck.bottom_up_layers                      |   0.145M             |   8.398M   |   51.84K     |\n",
            "|    neck.bottom_up_layers.0                   |    29.28K            |    4.216M  |    34.56K    |\n",
            "|    neck.bottom_up_layers.1                   |    0.116M            |    4.182M  |    17.28K    |\n",
            "|   neck.upsample_layers                       |                      |   34.56K   |   0          |\n",
            "|    neck.upsample_layers.0                    |                      |    11.52K  |    0         |\n",
            "|    neck.upsample_layers.1                    |                      |    23.04K  |    0         |\n",
            "|  bbox_head.head_module.convs_pred            |  6.792K              |  0.968M    |  18.144K     |\n",
            "|   bbox_head.head_module.convs_pred.0         |   0.984K             |   0.553M   |   13.824K    |\n",
            "|    bbox_head.head_module.convs_pred.0.weight |    (24, 40, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.0.bias   |    (24,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.1         |   1.944K             |   0.276M   |   3.456K     |\n",
            "|    bbox_head.head_module.convs_pred.1.weight |    (24, 80, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.1.bias   |    (24,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.2         |   3.864K             |   0.138M   |   0.864K     |\n",
            "|    bbox_head.head_module.convs_pred.2.weight |    (24, 160, 1, 1)   |            |              |\n",
            "|    bbox_head.head_module.convs_pred.2.bias   |    (24,)             |            |              |\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :  [1, 3, 192, 192]  \n",
            "    Model Flops     :       0.126G       \n",
            "  Model Parameters  :       0.945M       \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "05/21 00:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 88 .bias, 88 conv.weight, 85 other\n",
            "Loads checkpoint by local backend from path: Gesture_Detection_Swift-YOLO_192/pretrain.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.main_conv.conv.weight, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.conv.weight, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.conv.weight, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.conv.weight, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.conv.weight, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.main_conv.conv.weight, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.conv.weight, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.conv.weight, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.conv.weight, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.conv.weight, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.conv.weight, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.conv.weight, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.main_conv.conv.weight, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.conv.weight, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.conv.weight, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.conv.weight, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.conv.weight, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.conv.weight, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.conv.weight, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.conv.weight, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.conv.weight, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.main_conv.conv.weight, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.conv.weight, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.conv.weight, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.conv.weight, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.conv.weight, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.main_conv.conv.weight, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.conv.weight, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.conv.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.conv.weight, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.main_conv.conv.weight, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.conv.weight, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.conv.weight, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.conv.weight, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.conv.weight, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.main_conv.conv.weight, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.conv.weight, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.conv.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.conv.weight, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.conv.weight, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.conv.weight, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.conv.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.conv.weight\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.conv.conv.weight, backbone.stage1.1.main_conv.conv.norm.weight, backbone.stage1.1.main_conv.conv.norm.bias, backbone.stage1.1.main_conv.conv.norm.running_mean, backbone.stage1.1.main_conv.conv.norm.running_var, backbone.stage1.1.short_conv.conv.conv.weight, backbone.stage1.1.short_conv.conv.norm.weight, backbone.stage1.1.short_conv.conv.norm.bias, backbone.stage1.1.short_conv.conv.norm.running_mean, backbone.stage1.1.short_conv.conv.norm.running_var, backbone.stage1.1.final_conv.conv.conv.weight, backbone.stage1.1.final_conv.conv.norm.weight, backbone.stage1.1.final_conv.conv.norm.bias, backbone.stage1.1.final_conv.conv.norm.running_mean, backbone.stage1.1.final_conv.conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.conv.conv.weight, backbone.stage1.1.blocks.0.conv1.conv.norm.weight, backbone.stage1.1.blocks.0.conv1.conv.norm.bias, backbone.stage1.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.0.conv1.conv.norm.running_var, backbone.stage1.1.blocks.0.conv2.conv.conv.weight, backbone.stage1.1.blocks.0.conv2.conv.norm.weight, backbone.stage1.1.blocks.0.conv2.conv.norm.bias, backbone.stage1.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.0.conv2.conv.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.conv.weight, backbone.stage1.1.blocks.1.conv1.conv.norm.weight, backbone.stage1.1.blocks.1.conv1.conv.norm.bias, backbone.stage1.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.1.conv1.conv.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.conv.weight, backbone.stage1.1.blocks.1.conv2.conv.norm.weight, backbone.stage1.1.blocks.1.conv2.conv.norm.bias, backbone.stage1.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.1.conv2.conv.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.conv.weight, backbone.stage1.1.blocks.2.conv1.conv.norm.weight, backbone.stage1.1.blocks.2.conv1.conv.norm.bias, backbone.stage1.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.2.conv1.conv.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.conv.weight, backbone.stage1.1.blocks.2.conv2.conv.norm.weight, backbone.stage1.1.blocks.2.conv2.conv.norm.bias, backbone.stage1.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.2.conv2.conv.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.conv.conv.weight, backbone.stage2.1.main_conv.conv.norm.weight, backbone.stage2.1.main_conv.conv.norm.bias, backbone.stage2.1.main_conv.conv.norm.running_mean, backbone.stage2.1.main_conv.conv.norm.running_var, backbone.stage2.1.short_conv.conv.conv.weight, backbone.stage2.1.short_conv.conv.norm.weight, backbone.stage2.1.short_conv.conv.norm.bias, backbone.stage2.1.short_conv.conv.norm.running_mean, backbone.stage2.1.short_conv.conv.norm.running_var, backbone.stage2.1.final_conv.conv.conv.weight, backbone.stage2.1.final_conv.conv.norm.weight, backbone.stage2.1.final_conv.conv.norm.bias, backbone.stage2.1.final_conv.conv.norm.running_mean, backbone.stage2.1.final_conv.conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.conv.conv.weight, backbone.stage2.1.blocks.0.conv1.conv.norm.weight, backbone.stage2.1.blocks.0.conv1.conv.norm.bias, backbone.stage2.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.0.conv1.conv.norm.running_var, backbone.stage2.1.blocks.0.conv2.conv.conv.weight, backbone.stage2.1.blocks.0.conv2.conv.norm.weight, backbone.stage2.1.blocks.0.conv2.conv.norm.bias, backbone.stage2.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.0.conv2.conv.norm.running_var, backbone.stage2.1.blocks.1.conv1.conv.conv.weight, backbone.stage2.1.blocks.1.conv1.conv.norm.weight, backbone.stage2.1.blocks.1.conv1.conv.norm.bias, backbone.stage2.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.1.conv1.conv.norm.running_var, backbone.stage2.1.blocks.1.conv2.conv.conv.weight, backbone.stage2.1.blocks.1.conv2.conv.norm.weight, backbone.stage2.1.blocks.1.conv2.conv.norm.bias, backbone.stage2.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.1.conv2.conv.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.conv.weight, backbone.stage2.1.blocks.2.conv1.conv.norm.weight, backbone.stage2.1.blocks.2.conv1.conv.norm.bias, backbone.stage2.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.2.conv1.conv.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.conv.weight, backbone.stage2.1.blocks.2.conv2.conv.norm.weight, backbone.stage2.1.blocks.2.conv2.conv.norm.bias, backbone.stage2.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.2.conv2.conv.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.conv.weight, backbone.stage2.1.blocks.3.conv1.conv.norm.weight, backbone.stage2.1.blocks.3.conv1.conv.norm.bias, backbone.stage2.1.blocks.3.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.3.conv1.conv.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.conv.weight, backbone.stage2.1.blocks.3.conv2.conv.norm.weight, backbone.stage2.1.blocks.3.conv2.conv.norm.bias, backbone.stage2.1.blocks.3.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.3.conv2.conv.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.conv.weight, backbone.stage2.1.blocks.4.conv1.conv.norm.weight, backbone.stage2.1.blocks.4.conv1.conv.norm.bias, backbone.stage2.1.blocks.4.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.4.conv1.conv.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.conv.weight, backbone.stage2.1.blocks.4.conv2.conv.norm.weight, backbone.stage2.1.blocks.4.conv2.conv.norm.bias, backbone.stage2.1.blocks.4.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.4.conv2.conv.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.conv.weight, backbone.stage2.1.blocks.5.conv1.conv.norm.weight, backbone.stage2.1.blocks.5.conv1.conv.norm.bias, backbone.stage2.1.blocks.5.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.5.conv1.conv.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.conv.weight, backbone.stage2.1.blocks.5.conv2.conv.norm.weight, backbone.stage2.1.blocks.5.conv2.conv.norm.bias, backbone.stage2.1.blocks.5.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.5.conv2.conv.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.conv.conv.weight, backbone.stage3.1.main_conv.conv.norm.weight, backbone.stage3.1.main_conv.conv.norm.bias, backbone.stage3.1.main_conv.conv.norm.running_mean, backbone.stage3.1.main_conv.conv.norm.running_var, backbone.stage3.1.short_conv.conv.conv.weight, backbone.stage3.1.short_conv.conv.norm.weight, backbone.stage3.1.short_conv.conv.norm.bias, backbone.stage3.1.short_conv.conv.norm.running_mean, backbone.stage3.1.short_conv.conv.norm.running_var, backbone.stage3.1.final_conv.conv.conv.weight, backbone.stage3.1.final_conv.conv.norm.weight, backbone.stage3.1.final_conv.conv.norm.bias, backbone.stage3.1.final_conv.conv.norm.running_mean, backbone.stage3.1.final_conv.conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.conv.conv.weight, backbone.stage3.1.blocks.0.conv1.conv.norm.weight, backbone.stage3.1.blocks.0.conv1.conv.norm.bias, backbone.stage3.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.0.conv1.conv.norm.running_var, backbone.stage3.1.blocks.0.conv2.conv.conv.weight, backbone.stage3.1.blocks.0.conv2.conv.norm.weight, backbone.stage3.1.blocks.0.conv2.conv.norm.bias, backbone.stage3.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.0.conv2.conv.norm.running_var, backbone.stage3.1.blocks.1.conv1.conv.conv.weight, backbone.stage3.1.blocks.1.conv1.conv.norm.weight, backbone.stage3.1.blocks.1.conv1.conv.norm.bias, backbone.stage3.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.1.conv1.conv.norm.running_var, backbone.stage3.1.blocks.1.conv2.conv.conv.weight, backbone.stage3.1.blocks.1.conv2.conv.norm.weight, backbone.stage3.1.blocks.1.conv2.conv.norm.bias, backbone.stage3.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.1.conv2.conv.norm.running_var, backbone.stage3.1.blocks.2.conv1.conv.conv.weight, backbone.stage3.1.blocks.2.conv1.conv.norm.weight, backbone.stage3.1.blocks.2.conv1.conv.norm.bias, backbone.stage3.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.2.conv1.conv.norm.running_var, backbone.stage3.1.blocks.2.conv2.conv.conv.weight, backbone.stage3.1.blocks.2.conv2.conv.norm.weight, backbone.stage3.1.blocks.2.conv2.conv.norm.bias, backbone.stage3.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.2.conv2.conv.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.conv.weight, backbone.stage3.1.blocks.3.conv1.conv.norm.weight, backbone.stage3.1.blocks.3.conv1.conv.norm.bias, backbone.stage3.1.blocks.3.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.3.conv1.conv.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.conv.weight, backbone.stage3.1.blocks.3.conv2.conv.norm.weight, backbone.stage3.1.blocks.3.conv2.conv.norm.bias, backbone.stage3.1.blocks.3.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.3.conv2.conv.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.conv.weight, backbone.stage3.1.blocks.4.conv1.conv.norm.weight, backbone.stage3.1.blocks.4.conv1.conv.norm.bias, backbone.stage3.1.blocks.4.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.4.conv1.conv.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.conv.weight, backbone.stage3.1.blocks.4.conv2.conv.norm.weight, backbone.stage3.1.blocks.4.conv2.conv.norm.bias, backbone.stage3.1.blocks.4.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.4.conv2.conv.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.conv.weight, backbone.stage3.1.blocks.5.conv1.conv.norm.weight, backbone.stage3.1.blocks.5.conv1.conv.norm.bias, backbone.stage3.1.blocks.5.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.5.conv1.conv.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.conv.weight, backbone.stage3.1.blocks.5.conv2.conv.norm.weight, backbone.stage3.1.blocks.5.conv2.conv.norm.bias, backbone.stage3.1.blocks.5.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.5.conv2.conv.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.conv.weight, backbone.stage3.1.blocks.6.conv1.conv.norm.weight, backbone.stage3.1.blocks.6.conv1.conv.norm.bias, backbone.stage3.1.blocks.6.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.6.conv1.conv.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.conv.weight, backbone.stage3.1.blocks.6.conv2.conv.norm.weight, backbone.stage3.1.blocks.6.conv2.conv.norm.bias, backbone.stage3.1.blocks.6.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.6.conv2.conv.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.conv.weight, backbone.stage3.1.blocks.7.conv1.conv.norm.weight, backbone.stage3.1.blocks.7.conv1.conv.norm.bias, backbone.stage3.1.blocks.7.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.7.conv1.conv.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.conv.weight, backbone.stage3.1.blocks.7.conv2.conv.norm.weight, backbone.stage3.1.blocks.7.conv2.conv.norm.bias, backbone.stage3.1.blocks.7.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.7.conv2.conv.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.conv.weight, backbone.stage3.1.blocks.8.conv1.conv.norm.weight, backbone.stage3.1.blocks.8.conv1.conv.norm.bias, backbone.stage3.1.blocks.8.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.8.conv1.conv.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.conv.weight, backbone.stage3.1.blocks.8.conv2.conv.norm.weight, backbone.stage3.1.blocks.8.conv2.conv.norm.bias, backbone.stage3.1.blocks.8.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.8.conv2.conv.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.conv.conv.weight, backbone.stage4.1.main_conv.conv.norm.weight, backbone.stage4.1.main_conv.conv.norm.bias, backbone.stage4.1.main_conv.conv.norm.running_mean, backbone.stage4.1.main_conv.conv.norm.running_var, backbone.stage4.1.short_conv.conv.conv.weight, backbone.stage4.1.short_conv.conv.norm.weight, backbone.stage4.1.short_conv.conv.norm.bias, backbone.stage4.1.short_conv.conv.norm.running_mean, backbone.stage4.1.short_conv.conv.norm.running_var, backbone.stage4.1.final_conv.conv.conv.weight, backbone.stage4.1.final_conv.conv.norm.weight, backbone.stage4.1.final_conv.conv.norm.bias, backbone.stage4.1.final_conv.conv.norm.running_mean, backbone.stage4.1.final_conv.conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.conv.conv.weight, backbone.stage4.1.blocks.0.conv1.conv.norm.weight, backbone.stage4.1.blocks.0.conv1.conv.norm.bias, backbone.stage4.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.0.conv1.conv.norm.running_var, backbone.stage4.1.blocks.0.conv2.conv.conv.weight, backbone.stage4.1.blocks.0.conv2.conv.norm.weight, backbone.stage4.1.blocks.0.conv2.conv.norm.bias, backbone.stage4.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.0.conv2.conv.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.conv.weight, backbone.stage4.1.blocks.1.conv1.conv.norm.weight, backbone.stage4.1.blocks.1.conv1.conv.norm.bias, backbone.stage4.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.1.conv1.conv.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.conv.weight, backbone.stage4.1.blocks.1.conv2.conv.norm.weight, backbone.stage4.1.blocks.1.conv2.conv.norm.bias, backbone.stage4.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.1.conv2.conv.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.conv.weight, backbone.stage4.1.blocks.2.conv1.conv.norm.weight, backbone.stage4.1.blocks.2.conv1.conv.norm.bias, backbone.stage4.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.2.conv1.conv.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.conv.weight, backbone.stage4.1.blocks.2.conv2.conv.norm.weight, backbone.stage4.1.blocks.2.conv2.conv.norm.bias, backbone.stage4.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.2.conv2.conv.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.conv.conv.weight, neck.top_down_layers.0.0.main_conv.conv.norm.weight, neck.top_down_layers.0.0.main_conv.conv.norm.bias, neck.top_down_layers.0.0.main_conv.conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.conv.norm.running_var, neck.top_down_layers.0.0.short_conv.conv.conv.weight, neck.top_down_layers.0.0.short_conv.conv.norm.weight, neck.top_down_layers.0.0.short_conv.conv.norm.bias, neck.top_down_layers.0.0.short_conv.conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.conv.norm.running_var, neck.top_down_layers.0.0.final_conv.conv.conv.weight, neck.top_down_layers.0.0.final_conv.conv.norm.weight, neck.top_down_layers.0.0.final_conv.conv.norm.bias, neck.top_down_layers.0.0.final_conv.conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.conv.conv.weight, neck.top_down_layers.1.main_conv.conv.norm.weight, neck.top_down_layers.1.main_conv.conv.norm.bias, neck.top_down_layers.1.main_conv.conv.norm.running_mean, neck.top_down_layers.1.main_conv.conv.norm.running_var, neck.top_down_layers.1.short_conv.conv.conv.weight, neck.top_down_layers.1.short_conv.conv.norm.weight, neck.top_down_layers.1.short_conv.conv.norm.bias, neck.top_down_layers.1.short_conv.conv.norm.running_mean, neck.top_down_layers.1.short_conv.conv.norm.running_var, neck.top_down_layers.1.final_conv.conv.conv.weight, neck.top_down_layers.1.final_conv.conv.norm.weight, neck.top_down_layers.1.final_conv.conv.norm.bias, neck.top_down_layers.1.final_conv.conv.norm.running_mean, neck.top_down_layers.1.final_conv.conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.conv.conv.weight, neck.top_down_layers.1.blocks.0.conv1.conv.norm.weight, neck.top_down_layers.1.blocks.0.conv1.conv.norm.bias, neck.top_down_layers.1.blocks.0.conv1.conv.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.conv.conv.weight, neck.top_down_layers.1.blocks.0.conv2.conv.norm.weight, neck.top_down_layers.1.blocks.0.conv2.conv.norm.bias, neck.top_down_layers.1.blocks.0.conv2.conv.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.conv.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.conv.conv.weight, neck.bottom_up_layers.0.main_conv.conv.norm.weight, neck.bottom_up_layers.0.main_conv.conv.norm.bias, neck.bottom_up_layers.0.main_conv.conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.conv.norm.running_var, neck.bottom_up_layers.0.short_conv.conv.conv.weight, neck.bottom_up_layers.0.short_conv.conv.norm.weight, neck.bottom_up_layers.0.short_conv.conv.norm.bias, neck.bottom_up_layers.0.short_conv.conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.conv.norm.running_var, neck.bottom_up_layers.0.final_conv.conv.conv.weight, neck.bottom_up_layers.0.final_conv.conv.norm.weight, neck.bottom_up_layers.0.final_conv.conv.norm.bias, neck.bottom_up_layers.0.final_conv.conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.running_var, neck.bottom_up_layers.1.main_conv.conv.conv.weight, neck.bottom_up_layers.1.main_conv.conv.norm.weight, neck.bottom_up_layers.1.main_conv.conv.norm.bias, neck.bottom_up_layers.1.main_conv.conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.conv.norm.running_var, neck.bottom_up_layers.1.short_conv.conv.conv.weight, neck.bottom_up_layers.1.short_conv.conv.norm.weight, neck.bottom_up_layers.1.short_conv.conv.norm.bias, neck.bottom_up_layers.1.short_conv.conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.conv.norm.running_var, neck.bottom_up_layers.1.final_conv.conv.conv.weight, neck.bottom_up_layers.1.final_conv.conv.norm.weight, neck.bottom_up_layers.1.final_conv.conv.norm.bias, neck.bottom_up_layers.1.final_conv.conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.running_var\n",
            "\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.main_conv.conv.weight, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.conv.weight, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.conv.weight, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.conv.weight, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.conv.weight, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.main_conv.conv.weight, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.conv.weight, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.conv.weight, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.conv.weight, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.conv.weight, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.conv.weight, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.conv.weight, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.main_conv.conv.weight, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.conv.weight, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.conv.weight, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.conv.weight, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.conv.weight, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.conv.weight, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.conv.weight, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.conv.weight, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.conv.weight, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.main_conv.conv.weight, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.conv.weight, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.conv.weight, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.conv.weight, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.conv.weight, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.main_conv.conv.weight, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.conv.weight, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.conv.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.conv.weight, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.main_conv.conv.weight, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.conv.weight, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.conv.weight, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.conv.weight, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.conv.weight, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.main_conv.conv.weight, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.conv.weight, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.conv.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.conv.weight, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.conv.weight, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.conv.weight, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.conv.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.conv.weight\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.conv.conv.weight, backbone.stage1.1.main_conv.conv.norm.weight, backbone.stage1.1.main_conv.conv.norm.bias, backbone.stage1.1.main_conv.conv.norm.running_mean, backbone.stage1.1.main_conv.conv.norm.running_var, backbone.stage1.1.short_conv.conv.conv.weight, backbone.stage1.1.short_conv.conv.norm.weight, backbone.stage1.1.short_conv.conv.norm.bias, backbone.stage1.1.short_conv.conv.norm.running_mean, backbone.stage1.1.short_conv.conv.norm.running_var, backbone.stage1.1.final_conv.conv.conv.weight, backbone.stage1.1.final_conv.conv.norm.weight, backbone.stage1.1.final_conv.conv.norm.bias, backbone.stage1.1.final_conv.conv.norm.running_mean, backbone.stage1.1.final_conv.conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.conv.conv.weight, backbone.stage1.1.blocks.0.conv1.conv.norm.weight, backbone.stage1.1.blocks.0.conv1.conv.norm.bias, backbone.stage1.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.0.conv1.conv.norm.running_var, backbone.stage1.1.blocks.0.conv2.conv.conv.weight, backbone.stage1.1.blocks.0.conv2.conv.norm.weight, backbone.stage1.1.blocks.0.conv2.conv.norm.bias, backbone.stage1.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.0.conv2.conv.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.conv.weight, backbone.stage1.1.blocks.1.conv1.conv.norm.weight, backbone.stage1.1.blocks.1.conv1.conv.norm.bias, backbone.stage1.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.1.conv1.conv.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.conv.weight, backbone.stage1.1.blocks.1.conv2.conv.norm.weight, backbone.stage1.1.blocks.1.conv2.conv.norm.bias, backbone.stage1.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.1.conv2.conv.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.conv.weight, backbone.stage1.1.blocks.2.conv1.conv.norm.weight, backbone.stage1.1.blocks.2.conv1.conv.norm.bias, backbone.stage1.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage1.1.blocks.2.conv1.conv.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.conv.weight, backbone.stage1.1.blocks.2.conv2.conv.norm.weight, backbone.stage1.1.blocks.2.conv2.conv.norm.bias, backbone.stage1.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage1.1.blocks.2.conv2.conv.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.conv.conv.weight, backbone.stage2.1.main_conv.conv.norm.weight, backbone.stage2.1.main_conv.conv.norm.bias, backbone.stage2.1.main_conv.conv.norm.running_mean, backbone.stage2.1.main_conv.conv.norm.running_var, backbone.stage2.1.short_conv.conv.conv.weight, backbone.stage2.1.short_conv.conv.norm.weight, backbone.stage2.1.short_conv.conv.norm.bias, backbone.stage2.1.short_conv.conv.norm.running_mean, backbone.stage2.1.short_conv.conv.norm.running_var, backbone.stage2.1.final_conv.conv.conv.weight, backbone.stage2.1.final_conv.conv.norm.weight, backbone.stage2.1.final_conv.conv.norm.bias, backbone.stage2.1.final_conv.conv.norm.running_mean, backbone.stage2.1.final_conv.conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.conv.conv.weight, backbone.stage2.1.blocks.0.conv1.conv.norm.weight, backbone.stage2.1.blocks.0.conv1.conv.norm.bias, backbone.stage2.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.0.conv1.conv.norm.running_var, backbone.stage2.1.blocks.0.conv2.conv.conv.weight, backbone.stage2.1.blocks.0.conv2.conv.norm.weight, backbone.stage2.1.blocks.0.conv2.conv.norm.bias, backbone.stage2.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.0.conv2.conv.norm.running_var, backbone.stage2.1.blocks.1.conv1.conv.conv.weight, backbone.stage2.1.blocks.1.conv1.conv.norm.weight, backbone.stage2.1.blocks.1.conv1.conv.norm.bias, backbone.stage2.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.1.conv1.conv.norm.running_var, backbone.stage2.1.blocks.1.conv2.conv.conv.weight, backbone.stage2.1.blocks.1.conv2.conv.norm.weight, backbone.stage2.1.blocks.1.conv2.conv.norm.bias, backbone.stage2.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.1.conv2.conv.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.conv.weight, backbone.stage2.1.blocks.2.conv1.conv.norm.weight, backbone.stage2.1.blocks.2.conv1.conv.norm.bias, backbone.stage2.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.2.conv1.conv.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.conv.weight, backbone.stage2.1.blocks.2.conv2.conv.norm.weight, backbone.stage2.1.blocks.2.conv2.conv.norm.bias, backbone.stage2.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.2.conv2.conv.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.conv.weight, backbone.stage2.1.blocks.3.conv1.conv.norm.weight, backbone.stage2.1.blocks.3.conv1.conv.norm.bias, backbone.stage2.1.blocks.3.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.3.conv1.conv.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.conv.weight, backbone.stage2.1.blocks.3.conv2.conv.norm.weight, backbone.stage2.1.blocks.3.conv2.conv.norm.bias, backbone.stage2.1.blocks.3.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.3.conv2.conv.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.conv.weight, backbone.stage2.1.blocks.4.conv1.conv.norm.weight, backbone.stage2.1.blocks.4.conv1.conv.norm.bias, backbone.stage2.1.blocks.4.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.4.conv1.conv.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.conv.weight, backbone.stage2.1.blocks.4.conv2.conv.norm.weight, backbone.stage2.1.blocks.4.conv2.conv.norm.bias, backbone.stage2.1.blocks.4.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.4.conv2.conv.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.conv.weight, backbone.stage2.1.blocks.5.conv1.conv.norm.weight, backbone.stage2.1.blocks.5.conv1.conv.norm.bias, backbone.stage2.1.blocks.5.conv1.conv.norm.running_mean, backbone.stage2.1.blocks.5.conv1.conv.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.conv.weight, backbone.stage2.1.blocks.5.conv2.conv.norm.weight, backbone.stage2.1.blocks.5.conv2.conv.norm.bias, backbone.stage2.1.blocks.5.conv2.conv.norm.running_mean, backbone.stage2.1.blocks.5.conv2.conv.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.conv.conv.weight, backbone.stage3.1.main_conv.conv.norm.weight, backbone.stage3.1.main_conv.conv.norm.bias, backbone.stage3.1.main_conv.conv.norm.running_mean, backbone.stage3.1.main_conv.conv.norm.running_var, backbone.stage3.1.short_conv.conv.conv.weight, backbone.stage3.1.short_conv.conv.norm.weight, backbone.stage3.1.short_conv.conv.norm.bias, backbone.stage3.1.short_conv.conv.norm.running_mean, backbone.stage3.1.short_conv.conv.norm.running_var, backbone.stage3.1.final_conv.conv.conv.weight, backbone.stage3.1.final_conv.conv.norm.weight, backbone.stage3.1.final_conv.conv.norm.bias, backbone.stage3.1.final_conv.conv.norm.running_mean, backbone.stage3.1.final_conv.conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.conv.conv.weight, backbone.stage3.1.blocks.0.conv1.conv.norm.weight, backbone.stage3.1.blocks.0.conv1.conv.norm.bias, backbone.stage3.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.0.conv1.conv.norm.running_var, backbone.stage3.1.blocks.0.conv2.conv.conv.weight, backbone.stage3.1.blocks.0.conv2.conv.norm.weight, backbone.stage3.1.blocks.0.conv2.conv.norm.bias, backbone.stage3.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.0.conv2.conv.norm.running_var, backbone.stage3.1.blocks.1.conv1.conv.conv.weight, backbone.stage3.1.blocks.1.conv1.conv.norm.weight, backbone.stage3.1.blocks.1.conv1.conv.norm.bias, backbone.stage3.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.1.conv1.conv.norm.running_var, backbone.stage3.1.blocks.1.conv2.conv.conv.weight, backbone.stage3.1.blocks.1.conv2.conv.norm.weight, backbone.stage3.1.blocks.1.conv2.conv.norm.bias, backbone.stage3.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.1.conv2.conv.norm.running_var, backbone.stage3.1.blocks.2.conv1.conv.conv.weight, backbone.stage3.1.blocks.2.conv1.conv.norm.weight, backbone.stage3.1.blocks.2.conv1.conv.norm.bias, backbone.stage3.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.2.conv1.conv.norm.running_var, backbone.stage3.1.blocks.2.conv2.conv.conv.weight, backbone.stage3.1.blocks.2.conv2.conv.norm.weight, backbone.stage3.1.blocks.2.conv2.conv.norm.bias, backbone.stage3.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.2.conv2.conv.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.conv.weight, backbone.stage3.1.blocks.3.conv1.conv.norm.weight, backbone.stage3.1.blocks.3.conv1.conv.norm.bias, backbone.stage3.1.blocks.3.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.3.conv1.conv.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.conv.weight, backbone.stage3.1.blocks.3.conv2.conv.norm.weight, backbone.stage3.1.blocks.3.conv2.conv.norm.bias, backbone.stage3.1.blocks.3.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.3.conv2.conv.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.conv.weight, backbone.stage3.1.blocks.4.conv1.conv.norm.weight, backbone.stage3.1.blocks.4.conv1.conv.norm.bias, backbone.stage3.1.blocks.4.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.4.conv1.conv.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.conv.weight, backbone.stage3.1.blocks.4.conv2.conv.norm.weight, backbone.stage3.1.blocks.4.conv2.conv.norm.bias, backbone.stage3.1.blocks.4.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.4.conv2.conv.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.conv.weight, backbone.stage3.1.blocks.5.conv1.conv.norm.weight, backbone.stage3.1.blocks.5.conv1.conv.norm.bias, backbone.stage3.1.blocks.5.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.5.conv1.conv.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.conv.weight, backbone.stage3.1.blocks.5.conv2.conv.norm.weight, backbone.stage3.1.blocks.5.conv2.conv.norm.bias, backbone.stage3.1.blocks.5.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.5.conv2.conv.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.conv.weight, backbone.stage3.1.blocks.6.conv1.conv.norm.weight, backbone.stage3.1.blocks.6.conv1.conv.norm.bias, backbone.stage3.1.blocks.6.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.6.conv1.conv.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.conv.weight, backbone.stage3.1.blocks.6.conv2.conv.norm.weight, backbone.stage3.1.blocks.6.conv2.conv.norm.bias, backbone.stage3.1.blocks.6.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.6.conv2.conv.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.conv.weight, backbone.stage3.1.blocks.7.conv1.conv.norm.weight, backbone.stage3.1.blocks.7.conv1.conv.norm.bias, backbone.stage3.1.blocks.7.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.7.conv1.conv.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.conv.weight, backbone.stage3.1.blocks.7.conv2.conv.norm.weight, backbone.stage3.1.blocks.7.conv2.conv.norm.bias, backbone.stage3.1.blocks.7.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.7.conv2.conv.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.conv.weight, backbone.stage3.1.blocks.8.conv1.conv.norm.weight, backbone.stage3.1.blocks.8.conv1.conv.norm.bias, backbone.stage3.1.blocks.8.conv1.conv.norm.running_mean, backbone.stage3.1.blocks.8.conv1.conv.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.conv.weight, backbone.stage3.1.blocks.8.conv2.conv.norm.weight, backbone.stage3.1.blocks.8.conv2.conv.norm.bias, backbone.stage3.1.blocks.8.conv2.conv.norm.running_mean, backbone.stage3.1.blocks.8.conv2.conv.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.conv.conv.weight, backbone.stage4.1.main_conv.conv.norm.weight, backbone.stage4.1.main_conv.conv.norm.bias, backbone.stage4.1.main_conv.conv.norm.running_mean, backbone.stage4.1.main_conv.conv.norm.running_var, backbone.stage4.1.short_conv.conv.conv.weight, backbone.stage4.1.short_conv.conv.norm.weight, backbone.stage4.1.short_conv.conv.norm.bias, backbone.stage4.1.short_conv.conv.norm.running_mean, backbone.stage4.1.short_conv.conv.norm.running_var, backbone.stage4.1.final_conv.conv.conv.weight, backbone.stage4.1.final_conv.conv.norm.weight, backbone.stage4.1.final_conv.conv.norm.bias, backbone.stage4.1.final_conv.conv.norm.running_mean, backbone.stage4.1.final_conv.conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.conv.conv.weight, backbone.stage4.1.blocks.0.conv1.conv.norm.weight, backbone.stage4.1.blocks.0.conv1.conv.norm.bias, backbone.stage4.1.blocks.0.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.0.conv1.conv.norm.running_var, backbone.stage4.1.blocks.0.conv2.conv.conv.weight, backbone.stage4.1.blocks.0.conv2.conv.norm.weight, backbone.stage4.1.blocks.0.conv2.conv.norm.bias, backbone.stage4.1.blocks.0.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.0.conv2.conv.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.conv.weight, backbone.stage4.1.blocks.1.conv1.conv.norm.weight, backbone.stage4.1.blocks.1.conv1.conv.norm.bias, backbone.stage4.1.blocks.1.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.1.conv1.conv.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.conv.weight, backbone.stage4.1.blocks.1.conv2.conv.norm.weight, backbone.stage4.1.blocks.1.conv2.conv.norm.bias, backbone.stage4.1.blocks.1.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.1.conv2.conv.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.conv.weight, backbone.stage4.1.blocks.2.conv1.conv.norm.weight, backbone.stage4.1.blocks.2.conv1.conv.norm.bias, backbone.stage4.1.blocks.2.conv1.conv.norm.running_mean, backbone.stage4.1.blocks.2.conv1.conv.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.conv.weight, backbone.stage4.1.blocks.2.conv2.conv.norm.weight, backbone.stage4.1.blocks.2.conv2.conv.norm.bias, backbone.stage4.1.blocks.2.conv2.conv.norm.running_mean, backbone.stage4.1.blocks.2.conv2.conv.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.conv.conv.weight, neck.top_down_layers.0.0.main_conv.conv.norm.weight, neck.top_down_layers.0.0.main_conv.conv.norm.bias, neck.top_down_layers.0.0.main_conv.conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.conv.norm.running_var, neck.top_down_layers.0.0.short_conv.conv.conv.weight, neck.top_down_layers.0.0.short_conv.conv.norm.weight, neck.top_down_layers.0.0.short_conv.conv.norm.bias, neck.top_down_layers.0.0.short_conv.conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.conv.norm.running_var, neck.top_down_layers.0.0.final_conv.conv.conv.weight, neck.top_down_layers.0.0.final_conv.conv.norm.weight, neck.top_down_layers.0.0.final_conv.conv.norm.bias, neck.top_down_layers.0.0.final_conv.conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.conv.conv.weight, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.conv.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.conv.conv.weight, neck.top_down_layers.1.main_conv.conv.norm.weight, neck.top_down_layers.1.main_conv.conv.norm.bias, neck.top_down_layers.1.main_conv.conv.norm.running_mean, neck.top_down_layers.1.main_conv.conv.norm.running_var, neck.top_down_layers.1.short_conv.conv.conv.weight, neck.top_down_layers.1.short_conv.conv.norm.weight, neck.top_down_layers.1.short_conv.conv.norm.bias, neck.top_down_layers.1.short_conv.conv.norm.running_mean, neck.top_down_layers.1.short_conv.conv.norm.running_var, neck.top_down_layers.1.final_conv.conv.conv.weight, neck.top_down_layers.1.final_conv.conv.norm.weight, neck.top_down_layers.1.final_conv.conv.norm.bias, neck.top_down_layers.1.final_conv.conv.norm.running_mean, neck.top_down_layers.1.final_conv.conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.conv.conv.weight, neck.top_down_layers.1.blocks.0.conv1.conv.norm.weight, neck.top_down_layers.1.blocks.0.conv1.conv.norm.bias, neck.top_down_layers.1.blocks.0.conv1.conv.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.conv.conv.weight, neck.top_down_layers.1.blocks.0.conv2.conv.norm.weight, neck.top_down_layers.1.blocks.0.conv2.conv.norm.bias, neck.top_down_layers.1.blocks.0.conv2.conv.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.conv.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.conv.conv.weight, neck.bottom_up_layers.0.main_conv.conv.norm.weight, neck.bottom_up_layers.0.main_conv.conv.norm.bias, neck.bottom_up_layers.0.main_conv.conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.conv.norm.running_var, neck.bottom_up_layers.0.short_conv.conv.conv.weight, neck.bottom_up_layers.0.short_conv.conv.norm.weight, neck.bottom_up_layers.0.short_conv.conv.norm.bias, neck.bottom_up_layers.0.short_conv.conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.conv.norm.running_var, neck.bottom_up_layers.0.final_conv.conv.conv.weight, neck.bottom_up_layers.0.final_conv.conv.norm.weight, neck.bottom_up_layers.0.final_conv.conv.norm.bias, neck.bottom_up_layers.0.final_conv.conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.conv.conv.weight, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.conv.norm.running_var, neck.bottom_up_layers.1.main_conv.conv.conv.weight, neck.bottom_up_layers.1.main_conv.conv.norm.weight, neck.bottom_up_layers.1.main_conv.conv.norm.bias, neck.bottom_up_layers.1.main_conv.conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.conv.norm.running_var, neck.bottom_up_layers.1.short_conv.conv.conv.weight, neck.bottom_up_layers.1.short_conv.conv.norm.weight, neck.bottom_up_layers.1.short_conv.conv.norm.bias, neck.bottom_up_layers.1.short_conv.conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.conv.norm.running_var, neck.bottom_up_layers.1.final_conv.conv.conv.weight, neck.bottom_up_layers.1.final_conv.conv.norm.weight, neck.bottom_up_layers.1.final_conv.conv.norm.bias, neck.bottom_up_layers.1.final_conv.conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.conv.conv.weight, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.conv.norm.running_var\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      1/10     20.555   15.9797    3.1148    1.4605   0:03:21  : 100%|███████████| 92/92 [00:20<00:00,  4.60it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      2/10    19.8493   15.3296    3.1291    1.3907   0:02:49  : 100%|███████████| 92/92 [00:19<00:00,  4.71it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      3/10    19.5784   15.0693    3.1596    1.3495   0:02:26  : 100%|███████████| 92/92 [00:19<00:00,  4.61it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      4/10    19.4073   15.0835    3.0034    1.3204   0:02:03  : 100%|███████████| 92/92 [00:18<00:00,  4.90it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      5/10    19.2942   15.0714    2.9233    1.2995   0:01:43  : 100%|███████████| 92/92 [00:20<00:00,  4.49it/s]\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "   Mode     Epoch   data_time    time      eta    \n",
            "   val       5/10     0.1401    0.352    0:00:00  : 100%|███████████████████████████████| 11/11 [00:00<00:00, 11.05it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.39s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.30s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      6/10     18.919   14.9018    2.758     1.2592   0:01:23  : 100%|███████████| 92/92 [00:20<00:00,  4.44it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      7/10     18.81    14.8694    2.719     1.2216   0:01:02  : 100%|███████████| 92/92 [00:19<00:00,  4.66it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      8/10    18.6924   14.8074    2.7028    1.1822   0:00:41  : 100%|███████████| 92/92 [00:20<00:00,  4.46it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      9/10    18.5557   14.7118    2.6873    1.1566   0:00:20  : 100%|███████████| 92/92 [00:20<00:00,  4.44it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     10/10    18.3552   14.4962    2.7164    1.1426   0:00:00  : 100%|███████████| 92/92 [00:19<00:00,  4.71it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      10/10     0.0496    0.192     0.001     0.002      0.0       -1.0      0.0      0.002    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.55s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.61s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BssdsKjZaggO"
      },
      "source": [
        "## 📦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BVCW4-ABaggO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('Gesture_Detection_Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdmQNj06aggO",
        "outputId": "a365d3d7-e139-48c6-85d0-55a355da50e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input type (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): image\n",
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "05/21 00:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 652186554\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.9.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 652186554\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/21 00:13:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20240521_001332'}\n",
            "2024-05-21 00:13:35.363248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-21 00:13:35.363306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-21 00:13:35.365096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-21 00:13:36.557403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/21 00:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/21 00:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "  0%|                     | 0/100 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|███████████| 100/100 [00:12<00:00,  8.29it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:1043: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_0_f = torch.as_tensor(8, dtype=torch.float32, device=device_1_f)\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:1114: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_1_f = torch.as_tensor(16, dtype=torch.float32, device=device_3_f)\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:1185: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_2_f = torch.as_tensor(32, dtype=torch.float32, device=device_5_f)\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1614 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1623 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1660 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1668 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1704 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1712 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "Warning: TRANSPOSE 'contiguous_0_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 8, 576] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2853' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 24, 24, 24] and permutation is: [0 3 1 2]\n",
            "Info: PADV2 'input.37_transform_2' is a CPU only op\n",
            "Info: PADV2 'input.39_transform_2' is a CPU only op\n",
            "Info: PADV2 '2676_transform_2' is a CPU only op\n",
            "Warning: TRANSPOSE 'contiguous_1_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 8, 144] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2858' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 12, 12, 24] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'contiguous_2_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 8, 36] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2863' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 6, 6, 24] and permutation is: [0 3 1 2]\n",
            "<nng.Tensor 'input.37_transform_1_cpu' shape=[1, 6, 6, 80] dtype=int8> adding consumer <nng.Operation 'input0.49_te_transform1_avgpool' type=AvgPool>\n",
            "<nng.Tensor 'input.39_transform_1_cpu' shape=[1, 6, 6, 80] dtype=int8> adding consumer <nng.Operation 'input0.49_te_transform2_avgpool' type=AvgPool>\n",
            "<nng.Tensor '2676_transform_2_npu' shape=[1, 10, 10, 80] dtype=int8> adding consumer <nng.Operation 'fuse_transform_117' type=MaxPool>\n",
            "<nng.Tensor 'fuse_transform_117' shape=[1, 6, 6, 80] dtype=int8> adding consumer <nng.Operation 'input0.49_te_transform3_avgpool' type=AvgPool>\n",
            "\n",
            "Network summary for epoch_10_int8\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "Design peak SRAM bandwidth                       4.00 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.50 GB/s\n",
            "\n",
            "Total SRAM used                                259.06 KiB\n",
            "Total Off-chip Flash used                     1251.77 KiB\n",
            "\n",
            "CPU operators = 9 (4.6%)\n",
            "NPU operators = 187 (95.4%)\n",
            "\n",
            "Average SRAM bandwidth                           0.87 GB/s\n",
            "Input   SRAM bandwidth                           3.84 MB/batch\n",
            "Weight  SRAM bandwidth                           5.99 MB/batch\n",
            "Output  SRAM bandwidth                           2.21 MB/batch\n",
            "Total   SRAM bandwidth                          12.08 MB/batch\n",
            "Total   SRAM bandwidth            per input     12.08 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.09 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.08 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 1.20 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 1.28 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      1.28 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                         134698608 MACs/batch\n",
            "Network Tops/s                                   0.02 Tops/s\n",
            "\n",
            "NPU cycles                                    5751100 cycles/batch\n",
            "SRAM Access cycles                             945908 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                  1233792 cycles/batch\n",
            "Total cycles                                  6957676 cycles/batch\n",
            "\n",
            "Batch Inference time                13.92 ms,   71.86 inferences/s (batch size 1)\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "/content/ModelAssistant/sscma/models/heads/yolov5_head.py:125: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  xy = (feat_xy * 2 - 0.5 + grid) * torch.as_tensor(\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '670_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: inputs.1, fuse_attr_319_reshape, 670_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '670_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 670_te_transform, 670_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '670_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 670_te_transform_1_te_transform_2, fuse_attr_320_reshape, 670_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '706_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 670_te_transform_1, fuse_attr_322_reshape, 706_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '743_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 706_te_transform_1, fuse_attr_323_reshape, 743_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_33'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 743_te_transform, fuse_attr_324_reshape, fuse_transform_33\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_35'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_33, 706_te_transform_1, fuse_transform_35\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '778_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_35, fuse_attr_325_reshape, 778_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_51'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 778_te_transform, fuse_attr_326_reshape, fuse_transform_51\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_53'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_51, fuse_transform_35, fuse_transform_53\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '813_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_53, fuse_attr_327_reshape, 813_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_54'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 813_te_transform, fuse_attr_328_reshape, fuse_transform_54\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_57'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_54, fuse_transform_53, fuse_transform_57\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_58'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 670_te_transform_1, fuse_attr_321_reshape, fuse_transform_58\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '832_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_58, 832_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '850_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 832_te_transform, fuse_attr_329_reshape, 850_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '850_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 850_te_transform, 850_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '850_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 850_te_transform_1_te_transform_2, fuse_attr_330_reshape, 850_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '886_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 850_te_transform_1, fuse_attr_332_reshape, 886_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '926_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 886_te_transform_1, fuse_attr_333_reshape, 926_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_81'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 926_te_transform, fuse_attr_334_reshape, fuse_transform_81\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_83'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_81, 886_te_transform_1, fuse_transform_83\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '961_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_83, fuse_attr_335_reshape, 961_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_92'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 961_te_transform, fuse_attr_336_reshape, fuse_transform_92\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_94'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_92, fuse_transform_83, fuse_transform_94\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '996_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_94, fuse_attr_337_reshape, 996_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_107'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 996_te_transform, fuse_attr_338_reshape, fuse_transform_107\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_109'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_107, fuse_transform_94, fuse_transform_109\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1031_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_109, fuse_attr_339_reshape, 1031_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_112'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1031_te_transform, fuse_attr_340_reshape, fuse_transform_112\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_114'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_112, fuse_transform_109, fuse_transform_114\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1066_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_114, fuse_attr_341_reshape, 1066_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_21'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1066_te_transform, fuse_attr_342_reshape, fuse_transform_21\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_23'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_21, fuse_transform_114, fuse_transform_23\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1101_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_23, fuse_attr_343_reshape, 1101_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_24'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1101_te_transform, fuse_attr_344_reshape, fuse_transform_24\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_27'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_24, fuse_transform_23, fuse_transform_27\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_28'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 850_te_transform_1, fuse_attr_331_reshape, fuse_transform_28\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1120_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_28, 1120_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1120_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1120_te_transform, fuse_attr_345_reshape, 1120_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1138_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1120_te_transform_1, 1138_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1138_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1138_te_transform_1_te_transform_2, fuse_attr_346_reshape, 1138_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1174_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1138_te_transform_1, fuse_attr_348_reshape, 1174_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1217_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1174_te_transform_1, fuse_attr_349_reshape, 1217_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_42'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1217_te_transform, fuse_attr_350_reshape, fuse_transform_42\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_44'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_42, 1174_te_transform_1, fuse_transform_44\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1252_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_44, fuse_attr_351_reshape, 1252_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_60'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1252_te_transform, fuse_attr_352_reshape, fuse_transform_60\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_62'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_60, fuse_transform_44, fuse_transform_62\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1287_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_62, fuse_attr_353_reshape, 1287_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_69'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1287_te_transform, fuse_attr_354_reshape, fuse_transform_69\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_71'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_69, fuse_transform_62, fuse_transform_71\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1322_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_71, fuse_attr_355_reshape, 1322_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_75'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1322_te_transform, fuse_attr_356_reshape, fuse_transform_75\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_77'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_75, fuse_transform_71, fuse_transform_77\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1357_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_77, fuse_attr_357_reshape, 1357_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_84'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1357_te_transform, fuse_attr_358_reshape, fuse_transform_84\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_86'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_84, fuse_transform_77, fuse_transform_86\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1392_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_86, fuse_attr_359_reshape, 1392_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_95'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1392_te_transform, fuse_attr_360_reshape, fuse_transform_95\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_97'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_95, fuse_transform_86, fuse_transform_97\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1427_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_97, fuse_attr_361_reshape, 1427_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_101'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1427_te_transform, fuse_attr_362_reshape, fuse_transform_101\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_103'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_101, fuse_transform_97, fuse_transform_103\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1462_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_103, fuse_attr_363_reshape, 1462_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_120'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1462_te_transform, fuse_attr_364_reshape, fuse_transform_120\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_122'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_120, fuse_transform_103, fuse_transform_122\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1497_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_122, fuse_attr_365_reshape, 1497_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_146'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1497_te_transform, fuse_attr_366_reshape, fuse_transform_146\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_18'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_146, fuse_transform_122, fuse_transform_18\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_19'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1138_te_transform_1, fuse_attr_347_reshape, fuse_transform_19\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1516_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_19, 1516_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1516_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1516_te_transform, fuse_attr_367_reshape, 1516_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1535_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1516_te_transform_1, 1535_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1535_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1535_te_transform_1_te_transform_2, fuse_attr_368_reshape, 1535_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1571_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1535_te_transform_1, fuse_attr_370_reshape, 1571_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1608_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1571_te_transform_1, fuse_attr_371_reshape, 1608_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_36'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1608_te_transform, fuse_attr_372_reshape, fuse_transform_36\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_38'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_36, 1571_te_transform_1, fuse_transform_38\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1643_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_38, fuse_attr_373_reshape, 1643_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_48'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1643_te_transform, fuse_attr_374_reshape, fuse_transform_48\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_50'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_48, fuse_transform_38, fuse_transform_50\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1678_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_50, fuse_attr_375_reshape, 1678_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_63'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1678_te_transform, fuse_attr_376_reshape, fuse_transform_63\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_66'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_63, fuse_transform_50, fuse_transform_66\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_67'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1535_te_transform_1, fuse_attr_369_reshape, fuse_transform_67\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1697_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_67, 1697_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1716_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1697_te_transform, fuse_attr_377_reshape, 1716_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1716_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1716_te_transform, fuse_attr_378_reshape, 1716_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.39_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1716_te_transform_1, input.39_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.49_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'fuse_transform_90'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.49_transform_1, fuse_transform_90\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1749_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1, 1749_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1803_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1749_te_transform, fuse_attr_379_reshape, 1803_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1803_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1803_te_transform, fuse_attr_380_reshape, 1803_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_104'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1803_te_transform_1, fuse_transform_104\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_106'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1516_te_transform_1, fuse_transform_106\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1864_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_106, fuse_attr_382_reshape, 1864_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1880_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1864_te_transform, fuse_attr_383_reshape, 1880_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_117'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1880_te_transform, fuse_attr_384_reshape, fuse_transform_117\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_118'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_106, fuse_attr_381_reshape, fuse_transform_118\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1898_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_118, 1898_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1914_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1898_te_transform, fuse_attr_385_reshape, 1914_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1914_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1914_te_transform, fuse_attr_386_reshape, 1914_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_30'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1914_te_transform_1, fuse_transform_30\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_32'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1120_te_transform_1, fuse_transform_32\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1973_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_32, fuse_attr_388_reshape, 1973_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1989_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1973_te_transform, fuse_attr_389_reshape, 1989_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_39'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1989_te_transform, fuse_attr_390_reshape, fuse_transform_39\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_40'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_32, fuse_attr_387_reshape, fuse_transform_40\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2007_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_40, 2007_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2007_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2007_te_transform, fuse_attr_391_reshape, 2007_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_110'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2007_te_transform_1, fuse_attr_404_reshape, fuse_transform_110\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_111'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_110, fuse_transform_111\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.9, pred_map0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '270:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_.1, 270:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2647'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 270:0, 2646, 2647\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2649'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2647, 2648, 2649\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '284'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2649, grid.1, 284\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 284, 2650, xy.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 270:1, 2652, wh.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh.1, wh.1, wh0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh0.1, grid_.1, wh1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 270:2, 2654, cls.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh1.1, cls.1, out.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '315'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out.1, 315\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '2023_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2007_te_transform_1, 2023_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_45'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2023_te_transform_1_te_transform_2, fuse_attr_392_reshape, fuse_transform_45\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_47'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1914_te_transform_1, fuse_transform_47\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2080_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_47, fuse_attr_394_reshape, 2080_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2096_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2080_te_transform, fuse_attr_395_reshape, 2096_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_72'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2096_te_transform, fuse_attr_396_reshape, fuse_transform_72\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_73'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_47, fuse_attr_393_reshape, fuse_transform_73\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2114_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_73, 2114_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2114_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2114_te_transform, fuse_attr_397_reshape, 2114_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_115'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2114_te_transform_1, fuse_attr_405_reshape, fuse_transform_115\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_116'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_115, fuse_transform_116\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map1.1, pred_map2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '409:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_0.1, 409:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2657'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 409:0, 2656, 2657\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2659'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2657, 2658, 2659\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '423'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2659, grid0.1, 423\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 423, 2660, xy0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 409:1, 2662, wh2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh3.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh2.1, wh2.1, wh3.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh3.1, grid_0.1, wh4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 409:2, 2664, cls0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh4.1, cls0.1, out0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '454'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out0.1, 454\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '2130_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2114_te_transform_1, 2130_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_78'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2130_te_transform_1_te_transform_2, fuse_attr_398_reshape, fuse_transform_78\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_80'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1803_te_transform_1, fuse_transform_80\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2187_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_80, fuse_attr_400_reshape, 2187_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2203_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2187_te_transform, fuse_attr_401_reshape, 2203_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_98'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2203_te_transform, fuse_attr_402_reshape, fuse_transform_98\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_99'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_80, fuse_attr_399_reshape, fuse_transform_99\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2221_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_99, 2221_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'pred_map.1_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2221_te_transform, fuse_attr_403_reshape, pred_map.1_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_123'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.1_te_transform, fuse_attr_406_reshape, fuse_transform_123\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_124'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_123, fuse_transform_124\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map3.1, pred_map4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '548:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_1.1, 548:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2667'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 548:0, 2666, 2667\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2669'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2667, 2668, 2669\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '562'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2669, grid1.1, 562\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 562, 2670, xy1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh5.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 548:1, 2672, wh5.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh6.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh5.1, wh5.1, wh6.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh7.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh6.1, grid_1.1, wh7.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 548:2, 2674, cls1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh7.1, cls1.1, out1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '595'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out1.1, 595\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '598'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 454, 595, 598\n",
            "Warning: TRANSPOSE 'feat_.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map0.1' has data type: float32, Tensor 'feat_.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map.9' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_111' has data type: float32, Tensor 'pred_map.9' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_0.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map2.1' has data type: float32, Tensor 'feat_0.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_116' has data type: float32, Tensor 'pred_map1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map4.1' has data type: float32, Tensor 'feat_1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map3.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_124' has data type: float32, Tensor 'pred_map3.1' has data type: float32\n",
            "\n",
            "Network summary for epoch_10_float32\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "\n",
            "\n",
            "CPU operators = 179 (100.0%)\n",
            "NPU operators = 0 (0.0%)\n",
            "\n",
            "Neural network macs                                 0 MACs/batch\n",
            "Network Tops/s                                    nan Tops/s\n",
            "\n",
            "NPU cycles                                          0 cycles/batch\n",
            "SRAM Access cycles                                  0 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                        0 cycles/batch\n",
            "Total cycles                                        0 cycles/batch\n",
            "\n",
            "Batch Inference time                 0.00 ms,     nan inferences/s (batch size 1)\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "ONNX: Ignoring unsupported precision: int8\n",
            "Exported graph: graph(%input : Float(1, 3, 192, 192, strides=[110592, 36864, 192, 1], requires_grad=0, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.weight : Float(24, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.weight : Float(24, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.weight : Float(24, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %onnx::Conv_1102 : Float(16, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1103 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1105 : Float(24, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1106 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1108 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1109 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1111 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1112 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1114 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1115 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1117 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1118 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1120 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1121 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1123 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1124 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1126 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1127 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1129 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1130 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1132 : Float(24, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1133 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1135 : Float(40, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1136 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1138 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1139 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1141 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1142 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1144 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1145 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1147 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1148 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1150 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1151 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1153 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1154 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1156 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1157 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1159 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1160 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1162 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1163 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1165 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1166 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1168 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1169 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1171 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1172 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1174 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1175 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1177 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1178 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1180 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1181 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1183 : Float(80, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1184 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1186 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1187 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1189 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1190 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1192 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1193 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1195 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1196 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1198 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1199 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1201 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1202 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1204 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1205 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1207 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1208 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1210 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1211 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1213 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1214 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1216 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1217 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1219 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1220 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1222 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1223 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1225 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1226 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1228 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1229 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1231 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1232 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1234 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1235 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1237 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1238 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1240 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1241 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1243 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1244 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1246 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1247 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1249 : Float(160, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1250 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1252 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1253 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1255 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1256 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1258 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1259 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1261 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1262 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1264 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1265 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1267 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1268 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1270 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1271 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1273 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1274 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1276 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1277 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1279 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1280 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1282 : Float(160, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1283 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1285 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1286 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1288 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1289 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1291 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1292 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1294 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1295 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1297 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1298 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1300 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1301 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1303 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1304 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1306 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1307 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1309 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1310 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1312 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1313 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1315 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1316 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1318 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1319 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1321 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1322 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1324 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1325 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1327 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1328 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1330 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1331 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1333 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1334 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1336 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1337 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1339 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1340 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1342 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1343 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1345 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1346 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1348 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1349 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1351 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1352 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1354 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1355 : Float(160, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %/backbone/stem/conv/conv/Conv_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2], onnx_name=\"/backbone/stem/conv/conv/Conv\"](%input, %onnx::Conv_1102, %onnx::Conv_1103), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stem/conv/act/Relu_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stem/conv/act/Relu\"](%/backbone/stem/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.0/conv/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage1/stage1.0/conv/conv/Conv\"](%/backbone/stem/conv/act/Relu_output_0, %onnx::Conv_1105, %onnx::Conv_1106), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.0/conv/act/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.0/conv/act/Relu\"](%/backbone/stage1/stage1.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/short_conv/conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1108, %onnx::Conv_1109), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/short_conv/conv/act/Relu\"](%/backbone/stage1/stage1.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/main_conv/conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1111, %onnx::Conv_1112), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/main_conv/conv/act/Relu\"](%/backbone/stage1/stage1.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/backbone/stage1/stage1.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1114, %onnx::Conv_1115), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1117, %onnx::Conv_1118), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/backbone/stage1/stage1.1/main_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1120, %onnx::Conv_1121), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/act/Relu_output_0, %onnx::Conv_1123, %onnx::Conv_1124), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1126, %onnx::Conv_1127), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/act/Relu_output_0, %onnx::Conv_1129, %onnx::Conv_1130), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage1/stage1.1/Concat_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage1/stage1.1/Concat\"](%/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0, %/backbone/stage1/stage1.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/conv/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/final_conv/conv/conv/Conv\"](%/backbone/stage1/stage1.1/Concat_output_0, %onnx::Conv_1132, %onnx::Conv_1133), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/conv/act/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/final_conv/conv/act/Relu\"](%/backbone/stage1/stage1.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.0/conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage2/stage2.0/conv/conv/Conv\"](%/backbone/stage1/stage1.1/final_conv/conv/act/Relu_output_0, %onnx::Conv_1135, %onnx::Conv_1136), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.0/conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.0/conv/act/Relu\"](%/backbone/stage2/stage2.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/short_conv/conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1138, %onnx::Conv_1139), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/short_conv/conv/act/Relu\"](%/backbone/stage2/stage2.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/main_conv/conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1141, %onnx::Conv_1142), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/main_conv/conv/act/Relu\"](%/backbone/stage2/stage2.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1144, %onnx::Conv_1145), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1147, %onnx::Conv_1148), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/main_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1150, %onnx::Conv_1151), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/act/Relu_output_0, %onnx::Conv_1153, %onnx::Conv_1154), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1156, %onnx::Conv_1157), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/act/Relu_output_0, %onnx::Conv_1159, %onnx::Conv_1160), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1162, %onnx::Conv_1163), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/act/Relu_output_0, %onnx::Conv_1165, %onnx::Conv_1166), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1168, %onnx::Conv_1169), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/act/Relu_output_0, %onnx::Conv_1171, %onnx::Conv_1172), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1174, %onnx::Conv_1175), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/act/Relu_output_0, %onnx::Conv_1177, %onnx::Conv_1178), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage2/stage2.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage2/stage2.1/Concat\"](%/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0, %/backbone/stage2/stage2.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/final_conv/conv/conv/Conv\"](%/backbone/stage2/stage2.1/Concat_output_0, %onnx::Conv_1180, %onnx::Conv_1181), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/final_conv/conv/act/Relu\"](%/backbone/stage2/stage2.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.0/conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage3/stage3.0/conv/conv/Conv\"](%/backbone/stage2/stage2.1/final_conv/conv/act/Relu_output_0, %onnx::Conv_1183, %onnx::Conv_1184), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.0/conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.0/conv/act/Relu\"](%/backbone/stage3/stage3.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/short_conv/conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1186, %onnx::Conv_1187), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/short_conv/conv/act/Relu\"](%/backbone/stage3/stage3.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/main_conv/conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1189, %onnx::Conv_1190), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/main_conv/conv/act/Relu\"](%/backbone/stage3/stage3.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1192, %onnx::Conv_1193), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1195, %onnx::Conv_1196), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/main_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1198, %onnx::Conv_1199), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/act/Relu_output_0, %onnx::Conv_1201, %onnx::Conv_1202), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1204, %onnx::Conv_1205), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/act/Relu_output_0, %onnx::Conv_1207, %onnx::Conv_1208), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1210, %onnx::Conv_1211), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/act/Relu_output_0, %onnx::Conv_1213, %onnx::Conv_1214), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1216, %onnx::Conv_1217), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/act/Relu_output_0, %onnx::Conv_1219, %onnx::Conv_1220), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1222, %onnx::Conv_1223), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/act/Relu_output_0, %onnx::Conv_1225, %onnx::Conv_1226), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0, %onnx::Conv_1228, %onnx::Conv_1229), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/act/Relu_output_0, %onnx::Conv_1231, %onnx::Conv_1232), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0, %onnx::Conv_1234, %onnx::Conv_1235), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/act/Relu_output_0, %onnx::Conv_1237, %onnx::Conv_1238), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0, %onnx::Conv_1240, %onnx::Conv_1241), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/act/Relu_output_0, %onnx::Conv_1243, %onnx::Conv_1244), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage3/stage3.1/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage3/stage3.1/Concat\"](%/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0, %/backbone/stage3/stage3.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/final_conv/conv/conv/Conv\"](%/backbone/stage3/stage3.1/Concat_output_0, %onnx::Conv_1246, %onnx::Conv_1247), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/final_conv/conv/act/Relu\"](%/backbone/stage3/stage3.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.0/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage4/stage4.0/conv/conv/Conv\"](%/backbone/stage3/stage3.1/final_conv/conv/act/Relu_output_0, %onnx::Conv_1249, %onnx::Conv_1250), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.0/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.0/conv/act/Relu\"](%/backbone/stage4/stage4.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/short_conv/conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1252, %onnx::Conv_1253), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/short_conv/conv/act/Relu\"](%/backbone/stage4/stage4.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/main_conv/conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1255, %onnx::Conv_1256), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/main_conv/conv/act/Relu\"](%/backbone/stage4/stage4.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1258, %onnx::Conv_1259), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1261, %onnx::Conv_1262), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/backbone/stage4/stage4.1/main_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1264, %onnx::Conv_1265), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/act/Relu_output_0, %onnx::Conv_1267, %onnx::Conv_1268), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1270, %onnx::Conv_1271), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/act/Relu_output_0, %onnx::Conv_1273, %onnx::Conv_1274), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:137:0\n",
            "  %/backbone/stage4/stage4.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.1/Concat\"](%/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0, %/backbone/stage4/stage4.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/final_conv/conv/conv/Conv\"](%/backbone/stage4/stage4.1/Concat_output_0, %onnx::Conv_1276, %onnx::Conv_1277), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/final_conv/conv/act/Relu\"](%/backbone/stage4/stage4.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/final_conv/conv/act/Relu_output_0, %onnx::Conv_1279, %onnx::Conv_1280), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/poolings/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings/MaxPool\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_1/MaxPool\"](%/backbone/stage4/stage4.2/poolings/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_2/MaxPool\"](%/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/Concat_output_0 : Float(1, 320, 6, 6, strides=[11520, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.2/Concat\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0, %/backbone/stage4/stage4.2/poolings/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2 # /content/ModelAssistant/sscma/models/layers/sppf.py:68:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/Concat_output_0, %onnx::Conv_1282, %onnx::Conv_1283), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/reduce_layers.2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/reduce_layers.2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0, %onnx::Conv_1285, %onnx::Conv_1286), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/reduce_layers.2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/reduce_layers.2/conv/act/Relu\"](%/neck/reduce_layers.2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.0/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.0/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.0/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Resize_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.0/Resize\"](%/neck/reduce_layers.2/conv/act/Relu_output_0, %/neck/upsample_layers.0/Constant_1_output_0, %/neck/upsample_layers.0/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_output_0 : Float(1, 160, 12, 12, strides=[23040, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat\"](%/neck/upsample_layers.0/Resize_output_0, %/backbone/stage3/stage3.1/final_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1288, %onnx::Conv_1289), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1291, %onnx::Conv_1292), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/act/Relu_output_0, %onnx::Conv_1294, %onnx::Conv_1295), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1297, %onnx::Conv_1298), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/Concat\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0, %onnx::Conv_1300, %onnx::Conv_1301), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/act/Relu_output_0, %onnx::Conv_1303, %onnx::Conv_1304), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.1/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.1/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Resize_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.1/Resize\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0, %/neck/upsample_layers.1/Constant_1_output_0, %/neck/upsample_layers.1/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_1_output_0 : Float(1, 80, 24, 24, strides=[46080, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_1\"](%/neck/upsample_layers.1/Resize_output_0, %/backbone/stage2/stage2.1/final_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.1/short_conv/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/short_conv/conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1306, %onnx::Conv_1307), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/short_conv/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/short_conv/conv/act/Relu\"](%/neck/top_down_layers.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/main_conv/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/main_conv/conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1309, %onnx::Conv_1310), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/main_conv/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/main_conv/conv/act/Relu\"](%/neck/top_down_layers.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/neck/top_down_layers.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1312, %onnx::Conv_1313), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1315, %onnx::Conv_1316), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.1/Concat\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/neck/top_down_layers.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/neck/top_down_layers.1/final_conv/conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/final_conv/conv/conv/Conv\"](%/neck/top_down_layers.1/Concat_output_0, %onnx::Conv_1318, %onnx::Conv_1319), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/final_conv/conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/final_conv/conv/act/Relu\"](%/neck/top_down_layers.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.0/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.0/conv/conv/Conv\"](%/neck/top_down_layers.1/final_conv/conv/act/Relu_output_0, %onnx::Conv_1321, %onnx::Conv_1322), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.0/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.0/conv/act/Relu\"](%/neck/downsample_layers.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_2_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_2\"](%/neck/downsample_layers.0/conv/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/short_conv/conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1324, %onnx::Conv_1325), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/short_conv/conv/act/Relu\"](%/neck/bottom_up_layers.0/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/main_conv/conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1327, %onnx::Conv_1328), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/main_conv/conv/act/Relu\"](%/neck/bottom_up_layers.0/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/conv/Conv\"](%/neck/bottom_up_layers.0/main_conv/conv/act/Relu_output_0, %onnx::Conv_1330, %onnx::Conv_1331), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/conv/Conv\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1333, %onnx::Conv_1334), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.0/Concat\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/neck/bottom_up_layers.0/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/final_conv/conv/conv/Conv\"](%/neck/bottom_up_layers.0/Concat_output_0, %onnx::Conv_1336, %onnx::Conv_1337), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/final_conv/conv/act/Relu\"](%/neck/bottom_up_layers.0/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.1/conv/conv/Conv\"](%/neck/bottom_up_layers.0/final_conv/conv/act/Relu_output_0, %onnx::Conv_1339, %onnx::Conv_1340), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.1/conv/act/Relu\"](%/neck/downsample_layers.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_3_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_3\"](%/neck/downsample_layers.1/conv/act/Relu_output_0, %/neck/reduce_layers.2/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/short_conv/conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1342, %onnx::Conv_1343), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/short_conv/conv/act/Relu\"](%/neck/bottom_up_layers.1/short_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::short_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/main_conv/conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1345, %onnx::Conv_1346), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/main_conv/conv/act/Relu\"](%/neck/bottom_up_layers.1/main_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::main_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/conv/Conv\"](%/neck/bottom_up_layers.1/main_conv/conv/act/Relu_output_0, %onnx::Conv_1348, %onnx::Conv_1349), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/conv/Conv\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/act/Relu_output_0, %onnx::Conv_1351, %onnx::Conv_1352), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.1/Concat\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/act/Relu_output_0, %/neck/bottom_up_layers.1/short_conv/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:90:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/final_conv/conv/conv/Conv\"](%/neck/bottom_up_layers.1/Concat_output_0, %onnx::Conv_1354, %onnx::Conv_1355), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/final_conv/conv/act/Relu\"](%/neck/bottom_up_layers.1/final_conv/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.conv_module.ConvModule::final_conv/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/convs_pred.0/Conv_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.0/Conv\"](%/neck/top_down_layers.1/final_conv/conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.0.weight, %bbox_head.head_module.convs_pred.0.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid\"](%/convs_pred.0/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    8  576 [ CPULongType{4} ], onnx_name=\"/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_output_0 : Float(1, 3, 8, 576, strides=[13824, 4608, 576, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Sigmoid_output_0, %/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_output_0 : Float(1, 3, 576, 8, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose\"](%/Reshape_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.1/Conv_output_0 : Float(1, 24, 12, 12, strides=[3456, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.1/Conv\"](%/neck/bottom_up_layers.0/final_conv/conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.1.weight, %bbox_head.head_module.convs_pred.1.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_1_output_0 : Float(1, 24, 12, 12, strides=[3456, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_1\"](%/convs_pred.1/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    8  144 [ CPULongType{4} ], onnx_name=\"/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_1_output_0 : Float(1, 3, 8, 144, strides=[3456, 1152, 144, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%/Sigmoid_1_output_0, %/Constant_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_1_output_0 : Float(1, 3, 144, 8, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_1\"](%/Reshape_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.2/Conv_output_0 : Float(1, 24, 6, 6, strides=[864, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.2/Conv\"](%/neck/bottom_up_layers.1/final_conv/conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.2.weight, %bbox_head.head_module.convs_pred.2.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_2_output_0 : Float(1, 24, 6, 6, strides=[864, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_2\"](%/convs_pred.2/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3   8  36 [ CPULongType{4} ], onnx_name=\"/Constant_2\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_2_output_0 : Float(1, 3, 8, 36, strides=[864, 288, 36, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_2\"](%/Sigmoid_2_output_0, %/Constant_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_2_output_0 : Float(1, 3, 36, 8, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_2\"](%/Reshape_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/Constant_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 24  24 [ CPULongType{2} ], onnx_name=\"/Constant_3\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_4_output_0 : Long(24, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_4\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_output_0 : Long(24, 24, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_4_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_5_output_0 : Long(1, 24, strides=[24, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_5\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_1_output_0 : Long(24, 24, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_5_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze\"](%/Expand_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_1_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_1\"](%/Expand_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_output_0 : Long(24, 24, 2, strides=[48, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat\"](%/Unsqueeze_output_0, %/Unsqueeze_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_6_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  24  24   2 [ CPULongType{5} ], onnx_name=\"/Constant_6\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_7\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Constant_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_8\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/ConstantOfShape_output_0, %/Constant_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Constant_6_output_0, %/Mul_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_output_0, %/Constant_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_2_output_0 : Long(1, 1, 24, 24, 2, strides=[1152, 1152, 48, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Concat_output_0, %/Where_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_9\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_3_output_0 : Long(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_3\"](%/Expand_2_output_0, %/Constant_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast\"](%/Reshape_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_1_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_1\"](%/Cast_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_902 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    10  13  (1,2,.,.) =    16  30  (1,3,.,.) =    33  23 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_10_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  576    2 [ CPULongType{4} ], onnx_name=\"/Constant_10\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_11\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Constant_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_12\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Constant_10_output_0, %/Mul_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_1_output_0, %/Constant_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_3_output_0 : Long(1, 3, 576, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%onnx::Expand_902, %/Where_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_2\"](%/Expand_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_3\"](%/Cast_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_output_0 : Float(1, 3, 576, 2, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu), %/Split_output_1 : Float(1, 3, 576, 2, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu), %/Split_output_2 : Float(1, 3, 576, 4, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split\"](%/Transpose_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_13\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/Split_output_0, %/Constant_13_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_14\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub\"](%/Mul_2_output_0, %/Constant_14_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Sub_output_0, %/Cast_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant_15\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/Add_output_0, %/Constant_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_16\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_4_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_4\"](%/Split_output_1, %/Constant_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_5_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_5\"](%/Mul_4_output_0, %/Mul_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_6_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_6\"](%/Mul_5_output_0, %/Cast_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_17\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_7_output_0 : Float(1, 3, 576, 4, strides=[6912, 2304, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_7\"](%/Split_output_2, %/Constant_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_1_output_0 : Float(1, 3, 576, 8, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Mul_3_output_0, %/Mul_6_output_0, %/Mul_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_18\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_4_output_0 : Float(1, 1728, 8, strides=[13824, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_4\"](%/Concat_1_output_0, %/Constant_18_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_19_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 12  12 [ CPULongType{2} ], onnx_name=\"/Constant_19\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_20_output_0 : Long(12, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_20\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_4_output_0 : Long(12, 12, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_4\"](%/Constant_20_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_21_output_0 : Long(1, 12, strides=[12, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_21\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_5_output_0 : Long(12, 12, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_5\"](%/Constant_21_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_2_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_2\"](%/Expand_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_3_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_3\"](%/Expand_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_2_output_0 : Long(12, 12, 2, strides=[24, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_2\"](%/Unsqueeze_2_output_0, %/Unsqueeze_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_22_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  12  12   2 [ CPULongType{5} ], onnx_name=\"/Constant_22\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_23\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Constant_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_24\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_8_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_8\"](%/ConstantOfShape_2_output_0, %/Constant_24_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_2_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Constant_22_output_0, %/Mul_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_6_output_0 : Long(1, 1, 12, 12, 2, strides=[288, 288, 24, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_6\"](%/Concat_2_output_0, %/Where_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_25\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_5_output_0 : Long(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_5\"](%/Expand_6_output_0, %/Constant_25_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_4_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_4\"](%/Reshape_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_5_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_5\"](%/Cast_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_982 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    30  61  (1,2,.,.) =    62  45  (1,3,.,.) =     59  119 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_26_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  144    2 [ CPULongType{4} ], onnx_name=\"/Constant_26\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_27\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Constant_27_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_28_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_28\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_9\"](%/ConstantOfShape_3_output_0, %/Constant_28_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Constant_26_output_0, %/Mul_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_3\"](%/Equal_3_output_0, %/ConstantOfShape_3_output_0, %/Constant_26_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_7_output_0 : Long(1, 3, 144, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_7\"](%onnx::Expand_982, %/Where_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_6_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_6\"](%/Expand_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_7_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_7\"](%/Cast_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_1_output_0 : Float(1, 3, 144, 2, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu), %/Split_1_output_1 : Float(1, 3, 144, 2, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu), %/Split_1_output_2 : Float(1, 3, 144, 4, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split_1\"](%/Transpose_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_29_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_29\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_10_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_10\"](%/Split_1_output_0, %/Constant_29_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_30_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_30\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_1\"](%/Mul_10_output_0, %/Constant_30_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Sub_1_output_0, %/Cast_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_31_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/Constant_31\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_11_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_11\"](%/Add_1_output_0, %/Constant_31_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_32_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_32\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_12_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_12\"](%/Split_1_output_1, %/Constant_32_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_13_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_13\"](%/Mul_12_output_0, %/Mul_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_14_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_14\"](%/Mul_13_output_0, %/Cast_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_33_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_33\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_15_output_0 : Float(1, 3, 144, 4, strides=[1728, 576, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_15\"](%/Split_1_output_2, %/Constant_33_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_3_output_0 : Float(1, 3, 144, 8, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_3\"](%/Mul_11_output_0, %/Mul_14_output_0, %/Mul_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_34_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_34\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_6_output_0 : Float(1, 432, 8, strides=[3456, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_6\"](%/Concat_3_output_0, %/Constant_34_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_35_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 6  6 [ CPULongType{2} ], onnx_name=\"/Constant_35\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_36_output_0 : Long(6, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{6,1} ], onnx_name=\"/Constant_36\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_8_output_0 : Long(6, 6, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_8\"](%/Constant_36_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_37_output_0 : Long(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{1,6} ], onnx_name=\"/Constant_37\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_9_output_0 : Long(6, 6, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_9\"](%/Constant_37_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_4_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_4\"](%/Expand_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_5_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_5\"](%/Expand_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_4_output_0 : Long(6, 6, 2, strides=[12, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_4\"](%/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_38_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  6  6  2 [ CPULongType{5} ], onnx_name=\"/Constant_38\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_39\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_4\"](%/Constant_39_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_40_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_40\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_16_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_16\"](%/ConstantOfShape_4_output_0, %/Constant_40_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_4_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Constant_38_output_0, %/Mul_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_4\"](%/Equal_4_output_0, %/ConstantOfShape_4_output_0, %/Constant_38_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_10_output_0 : Long(1, 1, 6, 6, 2, strides=[72, 72, 12, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_10\"](%/Concat_4_output_0, %/Where_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_41_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_41\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_7_output_0 : Long(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_7\"](%/Expand_10_output_0, %/Constant_41_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_8_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_8\"](%/Reshape_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_9_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_9\"](%/Cast_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_1061 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    116   90  (1,2,.,.) =    156  198  (1,3,.,.) =    373  326 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_42_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3  36   2 [ CPULongType{4} ], onnx_name=\"/Constant_42\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_43\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_5\"](%/Constant_43_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_44_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_44\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_17\"](%/ConstantOfShape_5_output_0, %/Constant_44_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_5\"](%/Constant_42_output_0, %/Mul_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_5\"](%/Equal_5_output_0, %/ConstantOfShape_5_output_0, %/Constant_42_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_11_output_0 : Long(1, 3, 36, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_11\"](%onnx::Expand_1061, %/Where_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_10_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_10\"](%/Expand_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_11_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_11\"](%/Cast_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_2_output_0 : Float(1, 3, 36, 2, strides=[864, 288, 8, 1], requires_grad=0, device=cpu), %/Split_2_output_1 : Float(1, 3, 36, 2, strides=[864, 288, 8, 1], requires_grad=0, device=cpu), %/Split_2_output_2 : Float(1, 3, 36, 4, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split_2\"](%/Transpose_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_45_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_45\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_18_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_18\"](%/Split_2_output_0, %/Constant_45_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_46_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_46\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_2\"](%/Mul_18_output_0, %/Constant_46_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/Sub_2_output_0, %/Cast_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_47_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name=\"/Constant_47\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_19_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_19\"](%/Add_2_output_0, %/Constant_47_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_48_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_48\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_20_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_20\"](%/Split_2_output_1, %/Constant_48_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_21_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_21\"](%/Mul_20_output_0, %/Mul_20_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_22_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_22\"](%/Mul_21_output_0, %/Cast_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_49_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_49\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_23_output_0 : Float(1, 3, 36, 4, strides=[432, 144, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_23\"](%/Split_2_output_2, %/Constant_49_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_5_output_0 : Float(1, 3, 36, 8, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_5\"](%/Mul_19_output_0, %/Mul_22_output_0, %/Mul_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_50_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_50\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_8_output_0 : Float(1, 108, 8, strides=[864, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_8\"](%/Concat_5_output_0, %/Constant_50_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %output : Float(1, 2268, 8, strides=[18144, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_6\"](%/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:135:0\n",
            "  return (%output)\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "ONNX: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.onnx\n",
            "pnnxparam = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.pnnx.param\n",
            "pnnxbin = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.pnnx.bin\n",
            "pnnxpy = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.pnnx.py\n",
            "pnnxonnx = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.pnnx.onnx\n",
            "ncnnparam = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.ncnn.param\n",
            "ncnnbin = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.ncnn.bin\n",
            "ncnnpy = /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float.ncnn.py\n",
            "fp16 = 1\n",
            "optlevel = 2\n",
            "device = cpu\n",
            "inputshape = [1,3,192,192]f32\n",
            "inputshape2 = \n",
            "customop = \n",
            "moduleop = \n",
            "############# pass_level0\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "\n",
            "----------------\n",
            "\n",
            "############# pass_level1\n",
            "############# pass_level2\n",
            "############# pass_level3\n",
            "############# pass_level4\n",
            "############# pass_level5\n",
            "############# pass_ncnn\n"
          ]
        }
      ],
      "source": [
        "!sscma.export configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVEyAposaggO"
      },
      "source": [
        "### 📝Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB3587peaggP"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a89ppxgMaggP"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kV88CHEaggP"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yohtU4T4aggP"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ASqMQA-aggP"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGmTNuRRaggP"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hNCT1zEaggP"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo1GpZKuaggP",
        "outputId": "ffc1ae57-4490-4dc1-9165-f19a5de378c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.pkl\n",
            "05/21 00:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1051152216\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.9.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1051152216\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/21 00:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20240521_001601'}\n",
            "2024-05-21 00:16:04.069654: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-21 00:16:04.069711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-21 00:16:04.071265: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-21 00:16:05.260309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/21 00:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/21 00:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/166 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "05/21 00:16:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "05/21 00:16:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 166/166 [00:03<00:00, 42.34it/s]\n",
            "05/21 00:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
            "05/21 00:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.035 0.142 0.008 -1.000 0.035 0.046\n",
            "{'coco/bbox_mAP': 0.035, 'coco/bbox_mAP_50': 0.142, 'coco/bbox_mAP_75': 0.008, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.035, 'coco/bbox_mAP_l': 0.046}\n",
            "FPS: 72.142124 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EIZINZEaggP"
      },
      "source": [
        "## 🤖 Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ3Wo2fVaggP",
        "outputId": "69b53785-b5ee-4808-a194-cda25a4ca08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 79M\n",
            "drwxr-xr-x 3 root root 4.0K May 21 00:08 \u001b[0m\u001b[01;34m20240521_000823\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K May 21 00:13 \u001b[01;34m20240521_001332\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K May 21 00:16 \u001b[01;34m20240521_001601\u001b[0m/\n",
            "-rw-r--r-- 1 root root 7.9M May 21 00:12 best_coco_bbox_mAP_epoch_10.pth\n",
            "drwxr-xr-x 4 root root 4.0K May 21 00:03 \u001b[01;34mdataset\u001b[0m/\n",
            "-rw-r--r-- 1 root root  11M Jan  3 11:18 dataset.zip\n",
            "-rw-r--r-- 1 root root 4.4M May 21 00:14 epoch_10_float32.onnx\n",
            "-rw-r--r-- 1 root root 1.5K May 21 00:14 epoch_10_float32_summary_internal-default.csv\n",
            "-rw-r--r-- 1 root root 3.7M May 21 00:14 epoch_10_float32.tflite\n",
            "-rw-r--r-- 1 root root 3.7M May 21 00:14 epoch_10_float32_vela.tflite\n",
            "-rw-r--r-- 1 root root 1.9M May 21 00:14 epoch_10_float.ncnn.bin\n",
            "-rw-r--r-- 1 root root  19K May 21 00:14 epoch_10_float.ncnn.param\n",
            "-rw-r--r-- 1 root root  716 May 21 00:14 epoch_10_float.ncnn.py\n",
            "-rw-r--r-- 1 root root 3.7M May 21 00:14 epoch_10_float.pnnx.bin\n",
            "-rw-r--r-- 1 root root 1.9M May 21 00:14 epoch_10_float.pnnx.onnx\n",
            "-rw-r--r-- 1 root root  45K May 21 00:14 epoch_10_float.pnnx.param\n",
            "-rw-r--r-- 1 root root  57K May 21 00:14 epoch_10_float.pnnx.py\n",
            "-rw-r--r-- 1 root root  194 May 21 00:16 epoch_10_int8.pkl\n",
            "-rw-r--r-- 1 root root 1.6K May 21 00:14 epoch_10_int8_summary_internal-default.csv\n",
            "-rw-r--r-- 1 root root 1.1M May 21 00:14 epoch_10_int8.tflite\n",
            "-rw-r--r-- 1 root root 1.3M May 21 00:14 epoch_10_int8_vela.tflite\n",
            "-rw-r--r-- 1 root root  12M May 21 00:12 epoch_10.pth\n",
            "-rw-r--r-- 1 root root  12M May 21 00:10 epoch_5.pth\n",
            "-rw-r--r-- 1 root root   69 May 21 00:12 last_checkpoint\n",
            "-rw-r--r-- 1 root root  13M Nov 30 03:15 pretrain.pth\n",
            "drwxr-xr-x 2 root root 4.0K May 21 00:13 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw-r--r-- 1 root root  16K May 21 00:16 swift_yolo_tiny_1xb16_300e_coco.py\n",
            "-rw-r--r-- 1 root root  12K May 21 00:13 yolodetector_q_config.yml\n",
            "-rw-r--r-- 1 root root 3.9M May 21 00:13 yolodetector_q.pth\n",
            "-rw-r--r-- 1 root root 102K May 21 00:13 yolodetector_q.py\n"
          ]
        }
      ],
      "source": [
        "%ls -lh Gesture_Detection_Swift-YOLO_192/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5szyQXM0aggP"
      },
      "source": [
        "### Thanks for Trying Out SSCMA 🎉\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ✨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "edgelab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}